{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading libraries and Data sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'cleanedData/train_new.csv')\n",
    "df_test = pd.read_csv(r'cleanedData/test_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholder df into train\n",
    "df = df_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have to try three scalers MinMax,Standard & Robust to see which gives the best distribition of features on Gradeiant boost and random forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "label = df[\"Y\"]\n",
    "df.drop('Y',axis=1,inplace=True)\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "df['Y'] = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min max scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "label = df[\"Y\"]\n",
    "df.drop('Y',axis=1,inplace=True)\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "df['Y'] = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#robust scaller\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "label = df[\"Y\"]\n",
    "df.drop('Y',axis=1,inplace=True)\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "df['Y'] = label\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need a data split in train to evaluate the scalers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate the target variable from the features\n",
    "target = df['Y']\n",
    "# features = df[feature_names]\n",
    "features = df.drop('Y',axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FORREST WITH FEATURE IMPORTANCE AND ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Diagnosis: 0.23047963884205336\n",
      "1 # DME: 0.08573083635035664\n",
      "2 # Part B Labs: 0.0816587155649778\n",
      "3 # Labs: 0.06942327059966362\n",
      "4 # Part B E&M: 0.06842879634144829\n",
      "5 # Imaging: 0.0665009466670911\n",
      "6 # Hospital OP: 0.05797579363258395\n",
      "7 # Part B Drugs: 0.05564864328794769\n",
      "8 Avg. LOS: 0.03676443654708778\n",
      "9 Sex_encoded: 0.03390220667240632\n",
      "10 # All Physician OP: 0.030501348271127278\n",
      "11 Race_encoded: 0.028785476306882607\n",
      "12 HCC Score: 0.028139919429737117\n",
      "13 Age: 0.023889864066616247\n",
      "14 # ER: 0.02029231096106561\n",
      "15 # Part B Ambulance: 0.014382925064257408\n",
      "16 # Home Health: 0.012204117257983762\n",
      "17 # Dialysis: 0.011284556679877033\n",
      "18 # Inpatient: 0.011054610987720969\n",
      "19 Enrollment Months: 0.008317729109811033\n",
      "20 # Rx Claims: 0.008023931056663014\n",
      "21 # ER Admissions: 0.006427154932759368\n",
      "22 # SNF: 0.0034364473144452993\n",
      "23 # Miscellaneous: 0.0019965754968987227\n",
      "24 # Readmissions: 0.0015507807443760973\n",
      "25 # Rehabilitation Hospital: 0.001298849911767139\n",
      "26 # Hospice: 0.0009223052112606421\n",
      "27 # Psychiatric Hospital: 0.0005915947657819935\n",
      "28 # Total Claims: 0.00030591993868111914\n",
      "29 # Swing Bed SNF Claim: 8.02979866711832e-05\n",
      "30 # Long Term Stay Hospital: 0.0\n",
      "Confusion matrix:\n",
      "Predicted    0     1   All\n",
      "True                      \n",
      "0          343   900  1243\n",
      "1          300  3356  3656\n",
      "All        643  4256  4899\n",
      "Accuracy: 0.7550520514390692\n",
      "Precision: 0.7238093299951529\n",
      "Recall: 0.7550520514390692\n",
      "F1 Score: 0.7253766760338662\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "# Fit the classifier on the training set\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a dictionary of feature names and importances\n",
    "feature_importances = dict(zip(features.columns, importances))\n",
    "\n",
    "# Sort the dictionary by feature importance (descending order)\n",
    "sorted_importances = sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted list of feature names and importances\n",
    "n = 0\n",
    "for feature, importance in sorted_importances:\n",
    "    \n",
    "    print(f\"{n} {feature}: {importance}\")\n",
    "    n+=1\n",
    "# Use the trained model to predict on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "# Generate a confusion matrix and calculate the metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the confusion matrix and metrics\n",
    "print(\"Confusion matrix:\")\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADIANT BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "                      Feature  Importance\n",
      "0                   Diagnosis    0.456208\n",
      "1              # Part B Drugs    0.103018\n",
      "2                   HCC Score    0.094947\n",
      "3                  # Dialysis    0.075729\n",
      "4                    Avg. LOS    0.050706\n",
      "5                   # Imaging    0.030839\n",
      "6                      # Labs    0.028975\n",
      "7                       # DME    0.027723\n",
      "8               # Part B Labs    0.021553\n",
      "9               # Home Health    0.018292\n",
      "10              # Hospital OP    0.016405\n",
      "11         # Part B Ambulance    0.013151\n",
      "12         # All Physician OP    0.011737\n",
      "13                  # Hospice    0.007899\n",
      "14               # Part B E&M    0.007255\n",
      "15          Enrollment Months    0.004655\n",
      "16                # Rx Claims    0.004588\n",
      "17            # Miscellaneous    0.004455\n",
      "18            # ER Admissions    0.004326\n",
      "19                # Inpatient    0.003451\n",
      "20  # Rehabilitation Hospital    0.003310\n",
      "21                Sex_encoded    0.003240\n",
      "22     # Psychiatric Hospital    0.002426\n",
      "23                        Age    0.001975\n",
      "24                      # SNF    0.001496\n",
      "25               Race_encoded    0.001496\n",
      "26             # Readmissions    0.000143\n",
      "27      # Swing Bed SNF Claim    0.000000\n",
      "28                       # ER    0.000000\n",
      "29  # Long Term Stay Hospital    0.000000\n",
      "30             # Total Claims    0.000000\n",
      "Confusion matrix:\n",
      "Predicted    0     1   All\n",
      "True                      \n",
      "0          262   981  1243\n",
      "1          160  3496  3656\n",
      "All        422  4477  4899\n",
      "Accuracy: 0.7670953255766483\n",
      "Precision: 0.7402771698581966\n",
      "Recall: 0.7670953255766483\n",
      "F1 Score: 0.7214289685721423\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a Gradient Boosting Classifier model\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Fit the model to the data\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n",
    "# Get the feature importance\n",
    "feature_importance = gbc.feature_importances_\n",
    "\n",
    "# Rank the features from top to bottom\n",
    "feature_importance_df = pd.DataFrame({'Feature': features.columns, 'Importance': feature_importance})\n",
    "feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print the feature importance rankings\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Generate a confusion matrix and calculate the metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the confusion matrix and metrics\n",
    "print(\"Confusion matrix:\")\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small increment changes in random forrest so I will go with MinMax scaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'cleanedData/train_new.csv')\n",
    "df_test = pd.read_csv(r'cleanedData/test_new.csv')\n",
    "\n",
    "df = df_train\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "label = df[\"Y\"]\n",
    "df.drop('Y',axis=1,inplace=True)\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "df['Y'] = label\n",
    "df_train = df\n",
    "\n",
    "df = df_test\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "df_test = df\n",
    "\n",
    "df_train.to_csv(r'cleanedData/train_scalled.csv',index=False)\n",
    "df_test.to_csv(r'cleanedData/test_scalled.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "softec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
