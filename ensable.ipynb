{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'droppedDatasets/trainingSet.csv')\n",
    "df_test = pd.read_csv(r'droppedDatasets/testingSet.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target variable from the features\n",
    "target = df['Y']\n",
    "features = df.drop('Y',axis=1)\n",
    "# features = df[labels]\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.31, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FORREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "# Fit the classifier on the training set\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADIANT BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gradient Boosting Classifier model\n",
    "gbc = GradientBoostingClassifier()\n",
    "# Fit the model to the data\n",
    "gbc.fit(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LinearSVC model with L1 penalty and squared hinge loss\n",
    "model_l1 = LinearSVC(penalty=\"l1\", loss=\"squared_hinge\", dual=False, tol=1e-3)\n",
    "# Train the model on the selected features\n",
    "model_l1.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEARAL NETWORK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = y_train\n",
    "X = X_train\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(128, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0001), metrics=['accuracy'])\n",
    "def schedule(epoch, lr):    \n",
    "    if epoch > 5:\n",
    "        return lr * tf.math.exp(-0.01)\n",
    "    else:\n",
    "        return lr\n",
    "model_learningRate_schedular = tf.keras.callbacks.LearningRateScheduler(schedule, verbose=1)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0.05,\n",
    "    patience=20,\n",
    "    mode=\"auto\",\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "my_callbacks = [model_learningRate_schedular, early_stopping]\n",
    "# Fit the model to the data\n",
    "model.fit(X, y, epochs=100, batch_size=128, validation_data=(X_test,y_test),callbacks=my_callbacks)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEARAL NETWORK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "y = y_train\n",
    "X = X_train\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(128, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0001), metrics=['accuracy'])\n",
    "def schedule(epoch, lr):    \n",
    "    if epoch > 5:\n",
    "        return lr * tf.math.exp(-0.01)\n",
    "    else:\n",
    "        return lr\n",
    "model_learningRate_schedular = tf.keras.callbacks.LearningRateScheduler(schedule, verbose=1)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0.05,\n",
    "    patience=20,\n",
    "    mode=\"auto\",\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "my_callbacks = [model_learningRate_schedular, early_stopping]\n",
    "# Fit the model to the data\n",
    "model.fit(X, y, epochs=100, batch_size=128, validation_data=(X_test,y_test),callbacks=my_callbacks)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSAMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting(x, y, z):\n",
    "    \"\"\"\n",
    "    Performs majority voting on the predictions of three models\n",
    "    \n",
    "    Args:\n",
    "    pred1 (array-like): predicted class labels of model1\n",
    "    pred2 (array-like): predicted class labels of model2\n",
    "    pred3 (array-like): predicted class labels of model3\n",
    "    \n",
    "    Returns:\n",
    "    array-like: predicted class labels by majority voting\n",
    "    \"\"\"\n",
    "    ensemble_pred = []\n",
    "    for i in range(len(x)):\n",
    "        # count the occurrence of each class label\n",
    "        count = {0: 0, 1: 0} # assume we have three classes\n",
    "        count[x[i]] += 1\n",
    "        count[y[i]] += 1\n",
    "        count[z[i]] += 1\n",
    "        \n",
    "        # find the class label with the highest count\n",
    "        majority_label = max(count, key=count.get)\n",
    "        ensemble_pred.append(majority_label)\n",
    "        \n",
    "    return ensemble_pred\n",
    "x = model.predict(df_test)\n",
    "y = rf.predict(df_test)\n",
    "z = model_l1.predict(df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
