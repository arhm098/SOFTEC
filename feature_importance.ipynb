{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'Softec_Patient_Data_Training_Kaggle_V1_cleaned_final_v1.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DROPPING OLD Y LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.drop(['TotalCost_Y_Actual','TotalCost_Y_Expected'],axis=1,inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# initialize MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "label = df[\"Y\"]\n",
    "df.drop('Y',axis=1,inplace=True)\n",
    "# fit and transform the data\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# create a new dataframe with the scaled data\n",
    "df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "df['Y'] = label\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate the target variable from the features\n",
    "target = df['Y']\n",
    "# features = df[feature_names]\n",
    "features = df.drop('Y',axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OVERSAMPLING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#ros = RandomOverSampler(sampling_strategy=1) # Float\n",
    "ros = RandomOverSampler(sampling_strategy=\"not majority\") # String\n",
    "X_res, y_res = ros.fit_resample(df.drop('Y',axis=1),df['Y'])\n",
    "df = X_res\n",
    "df['Y'] = y_res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Diagnosis: 0.09310149531232326\n",
      "1 ID: 0.08117435521040561\n",
      "2 Avg ADI: 0.05345129867402497\n",
      "3 Zip Code: 0.05134299386068779\n",
      "4 Min ADI: 0.04967652587570024\n",
      "5 # Part B Labs: 0.04159666202090421\n",
      "6 Max ADI: 0.04084005571844863\n",
      "7 # DME: 0.03984489294247672\n",
      "8 # Hospital OP: 0.0363253175881028\n",
      "9 # Labs: 0.033891461250673355\n",
      "10 # Part B E&M: 0.03183158892998036\n",
      "11 # Part B Drugs: 0.03063260933267687\n",
      "12 SVI4: 0.03040260690562193\n",
      "13 SVI1: 0.029969455584206335\n",
      "14 # Imaging: 0.02955615924909489\n",
      "15 HCC Score: 0.02949511688374107\n",
      "16 SVI: 0.02941024032209644\n",
      "17 SVI3: 0.029374144184438903\n",
      "18 # Part B Imaging: 0.027030108386038122\n",
      "19 Avg. LOS: 0.019774344956224647\n",
      "20 # All Physician OP: 0.019239305251521833\n",
      "21 Sex: 0.0157490827448148\n",
      "22 insulin: 0.013817273222770095\n",
      "23 metformin hydrochloride: 0.012403704726050208\n",
      "24 glimepiride: 0.010693066841523536\n",
      "25 # ER: 0.010378784957050117\n",
      "26 MDI: 0.009359726470548347\n",
      "27 Enrollment Type Categorized: 0.007982330667254666\n",
      "28 Race_White: 0.007691688002139714\n",
      "29 # Part B Ambulance: 0.006943766720758209\n",
      "30 Age: 0.006665616180457844\n",
      "31 pioglitazone: 0.00643847601828409\n",
      "32 Race_Black: 0.005881805234625846\n",
      "33 # Home Health: 0.005652551808516334\n",
      "34 # Inpatient: 0.004782311573396863\n",
      "35 # Rx Claims: 0.004727281312328978\n",
      "36 # Short Term Stay Hospital: 0.004703845697776936\n",
      "37 Enrollment Months: 0.004380347395633132\n",
      "38 dapagliflozin: 0.0038070772346215555\n",
      "39 # ER Admissions: 0.0037159464850286517\n",
      "40 # Part-B Dialysis: 0.0035510913978931847\n",
      "41 # Dialysis: 0.003357785292716959\n",
      "42 sitagliptin and metformin hydrochloride: 0.0025548367563235277\n",
      "43 exenatide: 0.0022924056759320976\n",
      "44 Race_Asian: 0.0022212626677760943\n",
      "45 Race_UnKnown: 0.002137552963892454\n",
      "46 Race_Other Race: 0.0016060321946368317\n",
      "47 # SNF: 0.0014827371233598122\n",
      "48 # Non Swing Bed SNF Claim: 0.0012449196891500293\n",
      "49 Race_Hispanic: 0.0010457241603290866\n",
      "50 # Miscellaneous: 0.0008386735705852759\n",
      "51 % Readmissions: 0.0006737662113559765\n",
      "52 glyburide and metformin hydrochloride: 0.0006500009667367775\n",
      "53 # Readmissions: 0.0005594857403137372\n",
      "54 Race_North American Native: 0.0005461127700117899\n",
      "55 # Rehabilitation Hospital: 0.0005121517745742088\n",
      "56 # Total Claims: 0.00041892158040314573\n",
      "57 # Hospice: 0.0002942903044859642\n",
      "58 # Psychiatric Hospital: 0.00018104062523601882\n",
      "59 # Swing Bed SNF Claim: 9.267693894696454e-05\n",
      "60 # Long Term Stay Hospital: 3.10986237103425e-06\n",
      "Confusion matrix:\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          3145   549  3694\n",
      "1           297  3329  3626\n",
      "All        3442  3878  7320\n",
      "Accuracy: 0.8844262295081967\n",
      "Precision: 0.886329338191745\n",
      "Recall: 0.8844262295081967\n",
      "F1 Score: 0.8843261534988441\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load your data into a Pandas DataFrame called df\n",
    "# ...\n",
    "\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "rf = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "# Fit the classifier on the training set\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a dictionary of feature names and importances\n",
    "feature_importances = dict(zip(features.columns, importances))\n",
    "\n",
    "# Sort the dictionary by feature importance (descending order)\n",
    "sorted_importances = sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted list of feature names and importances\n",
    "n = 0\n",
    "for feature, importance in sorted_importances:\n",
    "    \n",
    "    print(f\"{n} {feature}: {importance}\")\n",
    "    n+=1\n",
    "# Use the trained model to predict on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "# Generate a confusion matrix and calculate the metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the confusion matrix and metrics\n",
    "print(\"Confusion matrix:\")\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          2810   846  3656\n",
      "1           407   836  1243\n",
      "All        3217  1682  4899\n",
      "Accuracy: 0.7442335170442947\n",
      "Precision: 0.7779678993996388\n",
      "Recall: 0.7442335170442947\n",
      "F1 Score: 0.7552586309682784\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Create a SVM classifier with a linear kernel\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "\n",
    "# Fit the model to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# Generate a confusion matrix and calculate the metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the confusion matrix and metrics\n",
    "print(\"Confusion matrix:\")\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# def f_importances(coef, names, top=-1):\n",
    "#     imp = coef\n",
    "#     imp, names = zip(*sorted(list(zip(imp, names))))\n",
    "\n",
    "#     # Show all features\n",
    "#     if top == -1:\n",
    "#         top = len(names)\n",
    "\n",
    "#     plt.barh(range(top), imp[::-1][0:top], align='center')\n",
    "#     plt.yticks(range(top), names[::-1][0:top])\n",
    "#     plt.show()\n",
    "\n",
    "# # Get feature importances and their names\n",
    "# importances = clf.coef_[0]\n",
    "# feature_names = df_processed.columns\n",
    "\n",
    "# # Create a dataframe with the feature importances\n",
    "# importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "# # Sort the dataframe by the absolute value of the feature importance\n",
    "# importances_df['Importance_Abs'] = importances_df['Importance'].abs()\n",
    "# importances_df_sorted = importances_df.sort_values('Importance_Abs', ascending=False).drop('Importance_Abs', axis=1)\n",
    "\n",
    "# # Print the sorted feature importances\n",
    "# for index, row in importances_df_sorted.iterrows():\n",
    "#     print(row['Feature'], row['Importance'])\n",
    "# # Specify your top n features you want to visualize.\n",
    "# # You can also discard the abs() function \n",
    "# # if you are interested in negative contribution of features\n",
    "# f_importances(abs(clf.coef_[0]), feature_names, top=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "           Feature  Importance\n",
      "0        Diagnosis    0.444652\n",
      "1        HCC Score    0.105942\n",
      "2   # Part B Drugs    0.093497\n",
      "3               ID    0.037425\n",
      "4         Avg. LOS    0.029412\n",
      "..             ...         ...\n",
      "56  # Total Claims    0.000000\n",
      "57     glimepiride    0.000000\n",
      "58       exenatide    0.000000\n",
      "59      Race_Black    0.000000\n",
      "60   Race_Hispanic    0.000000\n",
      "\n",
      "[61 rows x 2 columns]\n",
      "Confusion matrix:\n",
      "Predicted     0     1   All\n",
      "True                       \n",
      "0          2604  1052  3656\n",
      "1           445   798  1243\n",
      "All        3049  1850  4899\n",
      "Accuracy: 0.6944274341702388\n",
      "Precision: 0.7468010590541563\n",
      "Recall: 0.6944274341702388\n",
      "F1 Score: 0.7105800214254491\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a Gradient Boosting Classifier model\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Fit the model to the data\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n",
    "# Get the feature importance\n",
    "feature_importance = gbc.feature_importances_\n",
    "\n",
    "# Rank the features from top to bottom\n",
    "feature_importance_df = pd.DataFrame({'Feature': features.columns, 'Importance': feature_importance})\n",
    "feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print the feature importance rankings\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Generate a confusion matrix and calculate the metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the confusion matrix and metrics\n",
    "print(\"Confusion matrix:\")\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
      "Epoch 1/100\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.6382 - accuracy: 0.6321 - val_loss: 0.6157 - val_accuracy: 0.6730 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
      "Epoch 2/100\n",
      "382/382 [==============================] - 1s 4ms/step - loss: 0.6067 - accuracy: 0.6727 - val_loss: 0.6034 - val_accuracy: 0.6852 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
      "Epoch 3/100\n",
      "382/382 [==============================] - 1s 4ms/step - loss: 0.5991 - accuracy: 0.6782 - val_loss: 0.6039 - val_accuracy: 0.6877 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
      "Epoch 4/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.5938 - accuracy: 0.6838 - val_loss: 0.5950 - val_accuracy: 0.6950 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
      "Epoch 5/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.5899 - accuracy: 0.6866 - val_loss: 0.5854 - val_accuracy: 0.7010 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 9.999999747378752e-05.\n",
      "Epoch 6/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.5860 - accuracy: 0.6899 - val_loss: 0.5822 - val_accuracy: 0.7091 - lr: 1.0000e-04\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 9.900498116621748e-05.\n",
      "Epoch 7/100\n",
      "382/382 [==============================] - 1s 3ms/step - loss: 0.5824 - accuracy: 0.6923 - val_loss: 0.5847 - val_accuracy: 0.7034 - lr: 9.9005e-05\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 9.801986743696034e-05.\n",
      "Epoch 8/100\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.5789 - accuracy: 0.6968 - val_loss: 0.5750 - val_accuracy: 0.7116 - lr: 9.8020e-05\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 9.704455442260951e-05.\n",
      "Epoch 9/100\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.5756 - accuracy: 0.6979 - val_loss: 0.5947 - val_accuracy: 0.6944 - lr: 9.7045e-05\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 9.6078947535716e-05.\n",
      "Epoch 10/100\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.5727 - accuracy: 0.7004 - val_loss: 0.5784 - val_accuracy: 0.7091 - lr: 9.6079e-05\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 9.512294491287321e-05.\n",
      "Epoch 11/100\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.5696 - accuracy: 0.7021 - val_loss: 0.5795 - val_accuracy: 0.7071 - lr: 9.5123e-05\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 9.417645924258977e-05.\n",
      "Epoch 12/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5666 - accuracy: 0.7052 - val_loss: 0.5691 - val_accuracy: 0.7142 - lr: 9.4176e-05\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 9.323938866145909e-05.\n",
      "Epoch 13/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5638 - accuracy: 0.7086 - val_loss: 0.5673 - val_accuracy: 0.7189 - lr: 9.3239e-05\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 9.231163858203217e-05.\n",
      "Epoch 14/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5608 - accuracy: 0.7103 - val_loss: 0.5780 - val_accuracy: 0.7034 - lr: 9.2312e-05\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 9.139312169281766e-05.\n",
      "Epoch 15/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5580 - accuracy: 0.7107 - val_loss: 0.5668 - val_accuracy: 0.7130 - lr: 9.1393e-05\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 9.048374340636656e-05.\n",
      "Epoch 16/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5551 - accuracy: 0.7143 - val_loss: 0.5769 - val_accuracy: 0.7036 - lr: 9.0484e-05\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 8.95834164111875e-05.\n",
      "Epoch 17/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5524 - accuracy: 0.7159 - val_loss: 0.5640 - val_accuracy: 0.7195 - lr: 8.9583e-05\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 8.86920461198315e-05.\n",
      "Epoch 18/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5494 - accuracy: 0.7202 - val_loss: 0.5687 - val_accuracy: 0.7097 - lr: 8.8692e-05\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 8.78095452208072e-05.\n",
      "Epoch 19/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5471 - accuracy: 0.7195 - val_loss: 0.5475 - val_accuracy: 0.7291 - lr: 8.7810e-05\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 8.69358264026232e-05.\n",
      "Epoch 20/100\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.5442 - accuracy: 0.7238 - val_loss: 0.5608 - val_accuracy: 0.7191 - lr: 8.6936e-05\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 8.607080235378817e-05.\n",
      "Epoch 21/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5418 - accuracy: 0.7234 - val_loss: 0.5566 - val_accuracy: 0.7218 - lr: 8.6071e-05\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 8.521438576281071e-05.\n",
      "Epoch 22/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5389 - accuracy: 0.7257 - val_loss: 0.5386 - val_accuracy: 0.7365 - lr: 8.5214e-05\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 8.436648931819946e-05.\n",
      "Epoch 23/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5362 - accuracy: 0.7277 - val_loss: 0.5376 - val_accuracy: 0.7404 - lr: 8.4366e-05\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 8.352702570846304e-05.\n",
      "Epoch 24/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5340 - accuracy: 0.7298 - val_loss: 0.5399 - val_accuracy: 0.7342 - lr: 8.3527e-05\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 8.269591489806771e-05.\n",
      "Epoch 25/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5315 - accuracy: 0.7322 - val_loss: 0.5290 - val_accuracy: 0.7463 - lr: 8.2696e-05\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 8.187307685147971e-05.\n",
      "Epoch 26/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5289 - accuracy: 0.7334 - val_loss: 0.5487 - val_accuracy: 0.7295 - lr: 8.1873e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 8.105842425720766e-05.\n",
      "Epoch 27/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5267 - accuracy: 0.7353 - val_loss: 0.5445 - val_accuracy: 0.7299 - lr: 8.1058e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 8.025187707971781e-05.\n",
      "Epoch 28/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5239 - accuracy: 0.7370 - val_loss: 0.5508 - val_accuracy: 0.7267 - lr: 8.0252e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 7.945335528347641e-05.\n",
      "Epoch 29/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5218 - accuracy: 0.7385 - val_loss: 0.5332 - val_accuracy: 0.7404 - lr: 7.9453e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 7.86627788329497e-05.\n",
      "Epoch 30/100\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.5195 - accuracy: 0.7408 - val_loss: 0.5252 - val_accuracy: 0.7473 - lr: 7.8663e-05\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 7.788007496856153e-05.\n",
      "Epoch 31/100\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.5170 - accuracy: 0.7420 - val_loss: 0.5243 - val_accuracy: 0.7463 - lr: 7.7880e-05\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 7.710515637882054e-05.\n",
      "Epoch 32/100\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.5149 - accuracy: 0.7445 - val_loss: 0.5173 - val_accuracy: 0.7555 - lr: 7.7105e-05\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 7.633795030415058e-05.\n",
      "Epoch 33/100\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.5126 - accuracy: 0.7456 - val_loss: 0.5235 - val_accuracy: 0.7473 - lr: 7.6338e-05\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 7.55783767090179e-05.\n",
      "Epoch 34/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5102 - accuracy: 0.7482 - val_loss: 0.5117 - val_accuracy: 0.7561 - lr: 7.5578e-05\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 7.482636283384636e-05.\n",
      "Epoch 35/100\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.5080 - accuracy: 0.7512 - val_loss: 0.5121 - val_accuracy: 0.7597 - lr: 7.4826e-05\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 7.40818286431022e-05.\n",
      "Epoch 36/100\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.5061 - accuracy: 0.7519 - val_loss: 0.5112 - val_accuracy: 0.7585 - lr: 7.4082e-05\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 7.334470137720928e-05.\n",
      "Epoch 37/100\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.5037 - accuracy: 0.7530 - val_loss: 0.5047 - val_accuracy: 0.7622 - lr: 7.3345e-05\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 7.261490827659145e-05.\n",
      "Epoch 38/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.5017 - accuracy: 0.7544 - val_loss: 0.5171 - val_accuracy: 0.7553 - lr: 7.2615e-05\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 7.189237658167258e-05.\n",
      "Epoch 39/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4994 - accuracy: 0.7555 - val_loss: 0.5063 - val_accuracy: 0.7610 - lr: 7.1892e-05\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 7.117703353287652e-05.\n",
      "Epoch 40/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4973 - accuracy: 0.7590 - val_loss: 0.5176 - val_accuracy: 0.7534 - lr: 7.1177e-05\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 7.046881364658475e-05.\n",
      "Epoch 41/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4955 - accuracy: 0.7598 - val_loss: 0.5213 - val_accuracy: 0.7546 - lr: 7.0469e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 6.97676368872635e-05.\n",
      "Epoch 42/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4934 - accuracy: 0.7611 - val_loss: 0.4983 - val_accuracy: 0.7685 - lr: 6.9768e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 6.907343777129427e-05.\n",
      "Epoch 43/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4916 - accuracy: 0.7624 - val_loss: 0.4831 - val_accuracy: 0.7744 - lr: 6.9073e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 6.838614353910089e-05.\n",
      "Epoch 44/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4898 - accuracy: 0.7639 - val_loss: 0.4966 - val_accuracy: 0.7644 - lr: 6.8386e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 6.770568870706484e-05.\n",
      "Epoch 45/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4880 - accuracy: 0.7654 - val_loss: 0.4965 - val_accuracy: 0.7661 - lr: 6.7706e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 6.70320077915676e-05.\n",
      "Epoch 46/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4858 - accuracy: 0.7677 - val_loss: 0.5021 - val_accuracy: 0.7632 - lr: 6.7032e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 6.636502803303301e-05.\n",
      "Epoch 47/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4840 - accuracy: 0.7683 - val_loss: 0.4908 - val_accuracy: 0.7744 - lr: 6.6365e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 6.570468394784257e-05.\n",
      "Epoch 48/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4822 - accuracy: 0.7706 - val_loss: 0.5030 - val_accuracy: 0.7655 - lr: 6.5705e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 6.505091005237773e-05.\n",
      "Epoch 49/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4804 - accuracy: 0.7720 - val_loss: 0.4865 - val_accuracy: 0.7718 - lr: 6.5051e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 6.440364086301997e-05.\n",
      "Epoch 50/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4787 - accuracy: 0.7712 - val_loss: 0.5009 - val_accuracy: 0.7622 - lr: 6.4404e-05\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 6.376281089615077e-05.\n",
      "Epoch 51/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4768 - accuracy: 0.7734 - val_loss: 0.4727 - val_accuracy: 0.7838 - lr: 6.3763e-05\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 6.31283619441092e-05.\n",
      "Epoch 52/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4750 - accuracy: 0.7747 - val_loss: 0.4852 - val_accuracy: 0.7736 - lr: 6.3128e-05\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 6.250022124731913e-05.\n",
      "Epoch 53/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4736 - accuracy: 0.7753 - val_loss: 0.4861 - val_accuracy: 0.7730 - lr: 6.2500e-05\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 6.187833059811965e-05.\n",
      "Epoch 54/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4719 - accuracy: 0.7784 - val_loss: 0.4878 - val_accuracy: 0.7751 - lr: 6.1878e-05\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 6.126263178884983e-05.\n",
      "Epoch 55/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4701 - accuracy: 0.7799 - val_loss: 0.4809 - val_accuracy: 0.7791 - lr: 6.1263e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 6.065305933589116e-05.\n",
      "Epoch 56/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4686 - accuracy: 0.7809 - val_loss: 0.4758 - val_accuracy: 0.7814 - lr: 6.0653e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 6.0049551393603906e-05.\n",
      "Epoch 57/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4665 - accuracy: 0.7809 - val_loss: 0.4658 - val_accuracy: 0.7867 - lr: 6.0050e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 5.945204975432716e-05.\n",
      "Epoch 58/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4651 - accuracy: 0.7834 - val_loss: 0.4826 - val_accuracy: 0.7781 - lr: 5.9452e-05\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 5.886049257242121e-05.\n",
      "Epoch 59/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4635 - accuracy: 0.7845 - val_loss: 0.4767 - val_accuracy: 0.7816 - lr: 5.8860e-05\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 5.827482164022513e-05.\n",
      "Epoch 60/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4621 - accuracy: 0.7855 - val_loss: 0.4840 - val_accuracy: 0.7767 - lr: 5.8275e-05\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 5.769497875007801e-05.\n",
      "Epoch 61/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4604 - accuracy: 0.7870 - val_loss: 0.4868 - val_accuracy: 0.7755 - lr: 5.7695e-05\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 5.7120905694318935e-05.\n",
      "Epoch 62/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4590 - accuracy: 0.7889 - val_loss: 0.4642 - val_accuracy: 0.7902 - lr: 5.7121e-05\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 5.6552544265287e-05.\n",
      "Epoch 63/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4573 - accuracy: 0.7889 - val_loss: 0.4689 - val_accuracy: 0.7861 - lr: 5.6553e-05\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 5.598983625532128e-05.\n",
      "Epoch 64/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4561 - accuracy: 0.7906 - val_loss: 0.4624 - val_accuracy: 0.7904 - lr: 5.5990e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 5.5432727094739676e-05.\n",
      "Epoch 65/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4546 - accuracy: 0.7906 - val_loss: 0.4700 - val_accuracy: 0.7863 - lr: 5.5433e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 5.488116221386008e-05.\n",
      "Epoch 66/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4532 - accuracy: 0.7927 - val_loss: 0.4694 - val_accuracy: 0.7849 - lr: 5.4881e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 5.4335087043000385e-05.\n",
      "Epoch 67/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4515 - accuracy: 0.7934 - val_loss: 0.4685 - val_accuracy: 0.7889 - lr: 5.4335e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 5.379444337449968e-05.\n",
      "Epoch 68/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4502 - accuracy: 0.7948 - val_loss: 0.4475 - val_accuracy: 0.7977 - lr: 5.3794e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.325918027665466e-05.\n",
      "Epoch 69/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4486 - accuracy: 0.7962 - val_loss: 0.4725 - val_accuracy: 0.7816 - lr: 5.3259e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.2729243179783225e-05.\n",
      "Epoch 70/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4475 - accuracy: 0.7955 - val_loss: 0.4634 - val_accuracy: 0.7898 - lr: 5.2729e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 5.2204577514203265e-05.\n",
      "Epoch 71/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4462 - accuracy: 0.7977 - val_loss: 0.4683 - val_accuracy: 0.7849 - lr: 5.2205e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 5.168513234821148e-05.\n",
      "Epoch 72/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4449 - accuracy: 0.7978 - val_loss: 0.4614 - val_accuracy: 0.7906 - lr: 5.1685e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 5.1170856750104576e-05.\n",
      "Epoch 73/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4436 - accuracy: 0.7997 - val_loss: 0.4680 - val_accuracy: 0.7849 - lr: 5.1171e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 5.066169978817925e-05.\n",
      "Epoch 74/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4423 - accuracy: 0.8015 - val_loss: 0.4514 - val_accuracy: 0.7989 - lr: 5.0662e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 5.015760689275339e-05.\n",
      "Epoch 75/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4409 - accuracy: 0.8021 - val_loss: 0.4484 - val_accuracy: 0.7996 - lr: 5.0158e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 4.9658530770102516e-05.\n",
      "Epoch 76/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4399 - accuracy: 0.8020 - val_loss: 0.4573 - val_accuracy: 0.7955 - lr: 4.9659e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 4.916442048852332e-05.\n",
      "Epoch 77/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4384 - accuracy: 0.8043 - val_loss: 0.4505 - val_accuracy: 0.7975 - lr: 4.9164e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 4.8675225116312504e-05.\n",
      "Epoch 78/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4371 - accuracy: 0.8030 - val_loss: 0.4546 - val_accuracy: 0.7951 - lr: 4.8675e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 4.819089735974558e-05.\n",
      "Epoch 79/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4361 - accuracy: 0.8036 - val_loss: 0.4596 - val_accuracy: 0.7900 - lr: 4.8191e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 4.771138992509805e-05.\n",
      "Epoch 80/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4349 - accuracy: 0.8050 - val_loss: 0.4480 - val_accuracy: 0.7991 - lr: 4.7711e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 4.723665551864542e-05.\n",
      "Epoch 81/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4337 - accuracy: 0.8066 - val_loss: 0.4553 - val_accuracy: 0.7951 - lr: 4.7237e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 4.67666432086844e-05.\n",
      "Epoch 82/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4324 - accuracy: 0.8063 - val_loss: 0.4509 - val_accuracy: 0.7985 - lr: 4.6767e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 4.63013093394693e-05.\n",
      "Epoch 83/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4313 - accuracy: 0.8072 - val_loss: 0.4567 - val_accuracy: 0.7936 - lr: 4.6301e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 4.584060297929682e-05.\n",
      "Epoch 84/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4304 - accuracy: 0.8087 - val_loss: 0.4526 - val_accuracy: 0.7961 - lr: 4.5841e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 4.5384480472421274e-05.\n",
      "Epoch 85/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4290 - accuracy: 0.8083 - val_loss: 0.4545 - val_accuracy: 0.7918 - lr: 4.5384e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 4.493289816309698e-05.\n",
      "Epoch 86/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4278 - accuracy: 0.8103 - val_loss: 0.4369 - val_accuracy: 0.8077 - lr: 4.4933e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 4.448580875759944e-05.\n",
      "Epoch 87/100\n",
      "382/382 [==============================] - 2s 6ms/step - loss: 0.4267 - accuracy: 0.8103 - val_loss: 0.4516 - val_accuracy: 0.7955 - lr: 4.4486e-05\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 4.404316860018298e-05.\n",
      "Epoch 88/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4256 - accuracy: 0.8112 - val_loss: 0.4404 - val_accuracy: 0.8051 - lr: 4.4043e-05\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 4.36049303971231e-05.\n",
      "Epoch 89/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4245 - accuracy: 0.8118 - val_loss: 0.4412 - val_accuracy: 0.8051 - lr: 4.3605e-05\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 4.317105413065292e-05.\n",
      "Epoch 90/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4235 - accuracy: 0.8139 - val_loss: 0.4271 - val_accuracy: 0.8128 - lr: 4.3171e-05\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 4.274149614502676e-05.\n",
      "Epoch 91/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4227 - accuracy: 0.8134 - val_loss: 0.4387 - val_accuracy: 0.8053 - lr: 4.2741e-05\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 4.231621278449893e-05.\n",
      "Epoch 92/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4216 - accuracy: 0.8150 - val_loss: 0.4360 - val_accuracy: 0.8069 - lr: 4.2316e-05\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 4.189516039332375e-05.\n",
      "Epoch 93/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4202 - accuracy: 0.8167 - val_loss: 0.4607 - val_accuracy: 0.7865 - lr: 4.1895e-05\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.147829531575553e-05.\n",
      "Epoch 94/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4193 - accuracy: 0.8161 - val_loss: 0.4449 - val_accuracy: 0.8002 - lr: 4.1478e-05\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.1065581172006205e-05.\n",
      "Epoch 95/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4183 - accuracy: 0.8160 - val_loss: 0.4403 - val_accuracy: 0.8024 - lr: 4.1066e-05\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 4.065697066835128e-05.\n",
      "Epoch 96/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4171 - accuracy: 0.8183 - val_loss: 0.4332 - val_accuracy: 0.8083 - lr: 4.0657e-05\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 4.025242742500268e-05.\n",
      "Epoch 97/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4162 - accuracy: 0.8192 - val_loss: 0.4300 - val_accuracy: 0.8112 - lr: 4.0252e-05\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.9851907786214724e-05.\n",
      "Epoch 98/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4152 - accuracy: 0.8196 - val_loss: 0.4265 - val_accuracy: 0.8126 - lr: 3.9852e-05\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 3.945537537219934e-05.\n",
      "Epoch 99/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4142 - accuracy: 0.8197 - val_loss: 0.4302 - val_accuracy: 0.8100 - lr: 3.9455e-05\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 3.9062786527210847e-05.\n",
      "Epoch 100/100\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.4132 - accuracy: 0.8218 - val_loss: 0.4319 - val_accuracy: 0.8098 - lr: 3.9063e-05\n",
      "Feature Importance:\n",
      "                      Feature  Importance\n",
      "0                   # Imaging    3.538985\n",
      "1                    Zip Code    2.717891\n",
      "2                Race_UnKnown    2.676984\n",
      "3           Enrollment Months    2.660670\n",
      "4              % Readmissions    2.472322\n",
      "..                        ...         ...\n",
      "56                  # Hospice   -2.241904\n",
      "57            Race_Other Race   -2.307869\n",
      "58                 # Dialysis   -2.400022\n",
      "59              Race_Hispanic   -2.763213\n",
      "60  # Long Term Stay Hospital   -3.181881\n",
      "\n",
      "[61 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "y = y_train\n",
    "X = X_train\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(128, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0001), metrics=['accuracy'])\n",
    "def schedule(epoch, lr):    \n",
    "    if epoch > 5:\n",
    "        return lr * tf.math.exp(-0.01)\n",
    "    else:\n",
    "        return lr\n",
    "model_learningRate_schedular = tf.keras.callbacks.LearningRateScheduler(schedule, verbose=1)\n",
    "my_callbacks = [model_learningRate_schedular]\n",
    "# Fit the model to the data\n",
    "model.fit(X, y, epochs=100, batch_size=64, validation_data=(X_test,y_test),callbacks=my_callbacks)\n",
    "\n",
    "# Get the feature importance\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "feature_importance = np.sum(weights, axis=1)\n",
    "\n",
    "# Rank the features from top to bottom\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importance})\n",
    "feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print the feature importance rankings\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 5.96060181123903e-06.\n",
      "Epoch 1/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3337 - accuracy: 0.8673 - val_loss: 0.3624 - val_accuracy: 0.8489 - lr: 5.9606e-06\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 5.96060181123903e-06.\n",
      "Epoch 2/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3336 - accuracy: 0.8665 - val_loss: 0.3593 - val_accuracy: 0.8526 - lr: 5.9606e-06\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 5.96060181123903e-06.\n",
      "Epoch 3/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3334 - accuracy: 0.8673 - val_loss: 0.3602 - val_accuracy: 0.8514 - lr: 5.9606e-06\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 5.96060181123903e-06.\n",
      "Epoch 4/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3334 - accuracy: 0.8666 - val_loss: 0.3600 - val_accuracy: 0.8512 - lr: 5.9606e-06\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 5.96060181123903e-06.\n",
      "Epoch 5/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3332 - accuracy: 0.8678 - val_loss: 0.3568 - val_accuracy: 0.8545 - lr: 5.9606e-06\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 5.96060181123903e-06.\n",
      "Epoch 6/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3331 - accuracy: 0.8676 - val_loss: 0.3615 - val_accuracy: 0.8502 - lr: 5.9606e-06\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 5.901292752241716e-06.\n",
      "Epoch 7/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3330 - accuracy: 0.8673 - val_loss: 0.3612 - val_accuracy: 0.8500 - lr: 5.9013e-06\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 5.842573955305852e-06.\n",
      "Epoch 8/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3329 - accuracy: 0.8675 - val_loss: 0.3606 - val_accuracy: 0.8512 - lr: 5.8426e-06\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 5.784439508715877e-06.\n",
      "Epoch 9/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3328 - accuracy: 0.8680 - val_loss: 0.3608 - val_accuracy: 0.8504 - lr: 5.7844e-06\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 5.72688350075623e-06.\n",
      "Epoch 10/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3326 - accuracy: 0.8682 - val_loss: 0.3562 - val_accuracy: 0.8543 - lr: 5.7269e-06\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 5.669900019711349e-06.\n",
      "Epoch 11/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3326 - accuracy: 0.8678 - val_loss: 0.3594 - val_accuracy: 0.8512 - lr: 5.6699e-06\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 5.6134836086130235e-06.\n",
      "Epoch 12/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3324 - accuracy: 0.8673 - val_loss: 0.3613 - val_accuracy: 0.8498 - lr: 5.6135e-06\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 5.557628355745692e-06.\n",
      "Epoch 13/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3323 - accuracy: 0.8674 - val_loss: 0.3625 - val_accuracy: 0.8492 - lr: 5.5576e-06\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 5.502329258888494e-06.\n",
      "Epoch 14/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3322 - accuracy: 0.8678 - val_loss: 0.3602 - val_accuracy: 0.8500 - lr: 5.5023e-06\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 5.447580406325869e-06.\n",
      "Epoch 15/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3321 - accuracy: 0.8687 - val_loss: 0.3542 - val_accuracy: 0.8559 - lr: 5.4476e-06\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 5.393375886342255e-06.\n",
      "Epoch 16/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3320 - accuracy: 0.8679 - val_loss: 0.3551 - val_accuracy: 0.8541 - lr: 5.3934e-06\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 5.339711151464144e-06.\n",
      "Epoch 17/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3319 - accuracy: 0.8676 - val_loss: 0.3566 - val_accuracy: 0.8528 - lr: 5.3397e-06\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 5.286580289975973e-06.\n",
      "Epoch 18/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3318 - accuracy: 0.8685 - val_loss: 0.3589 - val_accuracy: 0.8518 - lr: 5.2866e-06\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 5.233977844909532e-06.\n",
      "Epoch 19/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3317 - accuracy: 0.8680 - val_loss: 0.3564 - val_accuracy: 0.8532 - lr: 5.2340e-06\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 5.1818988140439615e-06.\n",
      "Epoch 20/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3316 - accuracy: 0.8684 - val_loss: 0.3588 - val_accuracy: 0.8514 - lr: 5.1819e-06\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 5.1303381951584015e-06.\n",
      "Epoch 21/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3315 - accuracy: 0.8688 - val_loss: 0.3610 - val_accuracy: 0.8498 - lr: 5.1303e-06\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 5.0792905312846415e-06.\n",
      "Epoch 22/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3314 - accuracy: 0.8686 - val_loss: 0.3560 - val_accuracy: 0.8538 - lr: 5.0793e-06\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 5.028750820201822e-06.\n",
      "Epoch 23/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3313 - accuracy: 0.8684 - val_loss: 0.3612 - val_accuracy: 0.8502 - lr: 5.0288e-06\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 4.978714059689082e-06.\n",
      "Epoch 24/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3312 - accuracy: 0.8686 - val_loss: 0.3592 - val_accuracy: 0.8516 - lr: 4.9787e-06\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 4.9291752475255635e-06.\n",
      "Epoch 25/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3311 - accuracy: 0.8687 - val_loss: 0.3563 - val_accuracy: 0.8534 - lr: 4.9292e-06\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 4.880129381490406e-06.\n",
      "Epoch 26/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3310 - accuracy: 0.8683 - val_loss: 0.3545 - val_accuracy: 0.8549 - lr: 4.8801e-06\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 4.831571459362749e-06.\n",
      "Epoch 27/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3309 - accuracy: 0.8686 - val_loss: 0.3552 - val_accuracy: 0.8551 - lr: 4.8316e-06\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 4.783496478921734e-06.\n",
      "Epoch 28/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3308 - accuracy: 0.8684 - val_loss: 0.3576 - val_accuracy: 0.8518 - lr: 4.7835e-06\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 4.735899892693851e-06.\n",
      "Epoch 29/50\n",
      "382/382 [==============================] - 2s 5ms/step - loss: 0.3307 - accuracy: 0.8690 - val_loss: 0.3554 - val_accuracy: 0.8530 - lr: 4.7359e-06\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.688777153205592e-06.\n",
      "Epoch 30/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3306 - accuracy: 0.8690 - val_loss: 0.3566 - val_accuracy: 0.8530 - lr: 4.6888e-06\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 4.642123258236097e-06.\n",
      "Epoch 31/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3305 - accuracy: 0.8691 - val_loss: 0.3544 - val_accuracy: 0.8543 - lr: 4.6421e-06\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 4.595933205564506e-06.\n",
      "Epoch 32/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3305 - accuracy: 0.8695 - val_loss: 0.3575 - val_accuracy: 0.8522 - lr: 4.5959e-06\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 4.550202902464662e-06.\n",
      "Epoch 33/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3304 - accuracy: 0.8693 - val_loss: 0.3562 - val_accuracy: 0.8530 - lr: 4.5502e-06\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 4.5049278014630545e-06.\n",
      "Epoch 34/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3302 - accuracy: 0.8690 - val_loss: 0.3587 - val_accuracy: 0.8512 - lr: 4.5049e-06\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 4.460102900338825e-06.\n",
      "Epoch 35/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3302 - accuracy: 0.8691 - val_loss: 0.3578 - val_accuracy: 0.8512 - lr: 4.4601e-06\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 4.415724106365815e-06.\n",
      "Epoch 36/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3301 - accuracy: 0.8693 - val_loss: 0.3565 - val_accuracy: 0.8526 - lr: 4.4157e-06\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 4.3717868720705155e-06.\n",
      "Epoch 37/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3300 - accuracy: 0.8695 - val_loss: 0.3573 - val_accuracy: 0.8524 - lr: 4.3718e-06\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 4.328287104726769e-06.\n",
      "Epoch 38/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3299 - accuracy: 0.8691 - val_loss: 0.3609 - val_accuracy: 0.8485 - lr: 4.3283e-06\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 4.2852198021137156e-06.\n",
      "Epoch 39/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3298 - accuracy: 0.8687 - val_loss: 0.3556 - val_accuracy: 0.8532 - lr: 4.2852e-06\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 4.242581326252548e-06.\n",
      "Epoch 40/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3297 - accuracy: 0.8702 - val_loss: 0.3570 - val_accuracy: 0.8526 - lr: 4.2426e-06\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 4.2003671296697576e-06.\n",
      "Epoch 41/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3297 - accuracy: 0.8700 - val_loss: 0.3553 - val_accuracy: 0.8532 - lr: 4.2004e-06\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 4.158572664891835e-06.\n",
      "Epoch 42/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3296 - accuracy: 0.8693 - val_loss: 0.3537 - val_accuracy: 0.8543 - lr: 4.1586e-06\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 4.117194293939974e-06.\n",
      "Epoch 43/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3296 - accuracy: 0.8702 - val_loss: 0.3568 - val_accuracy: 0.8522 - lr: 4.1172e-06\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 4.076227469340665e-06.\n",
      "Epoch 44/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3294 - accuracy: 0.8698 - val_loss: 0.3562 - val_accuracy: 0.8518 - lr: 4.0762e-06\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 4.0356685531151015e-06.\n",
      "Epoch 45/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3293 - accuracy: 0.8697 - val_loss: 0.3536 - val_accuracy: 0.8547 - lr: 4.0357e-06\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 3.995512997789774e-06.\n",
      "Epoch 46/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3293 - accuracy: 0.8701 - val_loss: 0.3557 - val_accuracy: 0.8526 - lr: 3.9955e-06\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 3.955757165385876e-06.\n",
      "Epoch 47/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3292 - accuracy: 0.8698 - val_loss: 0.3526 - val_accuracy: 0.8559 - lr: 3.9558e-06\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 3.916396963177249e-06.\n",
      "Epoch 48/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3291 - accuracy: 0.8696 - val_loss: 0.3588 - val_accuracy: 0.8494 - lr: 3.9164e-06\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 3.877428298437735e-06.\n",
      "Epoch 49/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3291 - accuracy: 0.8700 - val_loss: 0.3552 - val_accuracy: 0.8526 - lr: 3.8774e-06\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 3.8388470784411766e-06.\n",
      "Epoch 50/50\n",
      "382/382 [==============================] - 2s 4ms/step - loss: 0.3290 - accuracy: 0.8694 - val_loss: 0.3539 - val_accuracy: 0.8543 - lr: 3.8388e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2396de45a30>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=50, batch_size=64, validation_data=(X_test,y_test),callbacks=my_callbacks)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "estimator = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# initialize the recursive feature elimination with cross-validation (RFECV) object\n",
    "rfecv = RFECV(estimator, step=1, cv=5)\n",
    "\n",
    "# fit the RFECV object to the data\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "# print the selected features and their rankings\n",
    "print(\"Selected Features: \")\n",
    "kept = []\n",
    "for feature, support in zip(X.columns, rfecv.support_):\n",
    "    if support:\n",
    "        print(f\"Feature {feature} is kept\")\n",
    "        kept += [feature]\n",
    "    else:\n",
    "        print(f\"Feature {feature} is eliminated\")\n",
    "\n",
    "print(\"Feature Rankings: \")\n",
    "for feature, rank in zip(X.columns, rfecv.ranking_):\n",
    "    print(f\"Feature {feature}: Rank {rank}\")\n",
    "\n",
    "y_pred = rfecv.predict(X_test)\n",
    "# Generate a confusion matrix and calculate the metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the confusion matrix and metrics\n",
    "print(\"Confusion matrix:\")\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "softec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
