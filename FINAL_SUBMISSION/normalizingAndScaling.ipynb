{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading libraries and Data sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'cleanedData/train_new.csv')\n",
    "df_test = pd.read_csv(r'cleanedData/test_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#placeholder df into train\n",
    "df = df_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have to try three scalers MinMax,Standard & Robust to see which gives the best distribition of features on Gradeiant boost and random forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "label = df[\"Y\"]\n",
    "df.drop('Y',axis=1,inplace=True)\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "df['Y'] = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min max scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "label = df[\"Y\"]\n",
    "df.drop('Y',axis=1,inplace=True)\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "df['Y'] = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#robust scaller\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "label = df[\"Y\"]\n",
    "df.drop('Y',axis=1,inplace=True)\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "df['Y'] = label\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need a data split in train to evaluate the scalers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate the target variable from the features\n",
    "target = df['Y']\n",
    "# features = df[feature_names]\n",
    "features = df.drop('Y',axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FORREST WITH FEATURE IMPORTANCE AND ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Diagnosis: 0.225719729321158\n",
      "1 # DME: 0.08808729733232988\n",
      "2 # Part B Labs: 0.08174984963723768\n",
      "3 # Part B E&M: 0.06888798961556525\n",
      "4 # Labs: 0.06605220762991611\n",
      "5 # Imaging: 0.06553723384416463\n",
      "6 # Part B Drugs: 0.056067017439692404\n",
      "7 # Hospital OP: 0.055243651006917895\n",
      "8 Avg. LOS: 0.03603564061267004\n",
      "9 Sex_encoded: 0.03396043751769654\n",
      "10 HCC Score: 0.02961533777596917\n",
      "11 # All Physician OP: 0.02822056208300337\n",
      "12 Race_encoded: 0.027747221208175334\n",
      "13 Age: 0.02346539326281624\n",
      "14 # ER: 0.020934819962682934\n",
      "15 # Part B Ambulance: 0.013925327777141705\n",
      "16 # Home Health: 0.013237651720506647\n",
      "17 State_encoded: 0.010929336491324396\n",
      "18 # Inpatient: 0.01069020194851883\n",
      "19 # Dialysis: 0.010517811936393262\n",
      "20 Enrollment Months: 0.008545587645644897\n",
      "21 # Rx Claims: 0.008301112510117857\n",
      "22 # ER Admissions: 0.006274684446012417\n",
      "23 # SNF: 0.003515210572825994\n",
      "24 # Miscellaneous: 0.0016841058233750508\n",
      "25 # Readmissions: 0.0016225834280808973\n",
      "26 # Hospice: 0.0012133755926756983\n",
      "27 # Rehabilitation Hospital: 0.001094212431717612\n",
      "28 # Psychiatric Hospital: 0.0006876229746708519\n",
      "29 # Total Claims: 0.00038532147892159205\n",
      "30 # Swing Bed SNF Claim: 5.14649720767916e-05\n",
      "31 # Long Term Stay Hospital: 0.0\n",
      "Confusion matrix:\n",
      "Predicted    0     1   All\n",
      "True                      \n",
      "0          337   906  1243\n",
      "1          308  3348  3656\n",
      "All        645  4254  4899\n",
      "Accuracy: 0.752194325372525\n",
      "Precision: 0.7199026479583132\n",
      "Recall: 0.752194325372525\n",
      "F1 Score: 0.7223167938466868\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "# Fit the classifier on the training set\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a dictionary of feature names and importances\n",
    "feature_importances = dict(zip(features.columns, importances))\n",
    "\n",
    "# Sort the dictionary by feature importance (descending order)\n",
    "sorted_importances = sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted list of feature names and importances\n",
    "n = 0\n",
    "for feature, importance in sorted_importances:\n",
    "    \n",
    "    print(f\"{n} {feature}: {importance}\")\n",
    "    n+=1\n",
    "# Use the trained model to predict on the test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "# Generate a confusion matrix and calculate the metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the confusion matrix and metrics\n",
    "print(\"Confusion matrix:\")\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADIANT BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "                      Feature  Importance\n",
      "0                   Diagnosis    0.456553\n",
      "1              # Part B Drugs    0.103538\n",
      "2                   HCC Score    0.095497\n",
      "3                  # Dialysis    0.076096\n",
      "4                    Avg. LOS    0.048478\n",
      "5                   # Imaging    0.031027\n",
      "6                      # Labs    0.027477\n",
      "7                       # DME    0.027367\n",
      "8               # Part B Labs    0.021233\n",
      "9               # Home Health    0.018321\n",
      "10              # Hospital OP    0.015016\n",
      "11         # Part B Ambulance    0.012545\n",
      "12         # All Physician OP    0.012479\n",
      "13                  # Hospice    0.007974\n",
      "14               # Part B E&M    0.006729\n",
      "15                # Inpatient    0.005135\n",
      "16                # Rx Claims    0.004826\n",
      "17          Enrollment Months    0.004523\n",
      "18            # ER Admissions    0.004378\n",
      "19            # Miscellaneous    0.004374\n",
      "20                Sex_encoded    0.003674\n",
      "21  # Rehabilitation Hospital    0.003522\n",
      "22     # Psychiatric Hospital    0.002392\n",
      "23              State_encoded    0.001989\n",
      "24                      # SNF    0.001573\n",
      "25                        Age    0.001541\n",
      "26               Race_encoded    0.000997\n",
      "27                       # ER    0.000484\n",
      "28             # Readmissions    0.000261\n",
      "29  # Long Term Stay Hospital    0.000000\n",
      "30             # Total Claims    0.000000\n",
      "31      # Swing Bed SNF Claim    0.000000\n",
      "Confusion matrix:\n",
      "Predicted    0     1   All\n",
      "True                      \n",
      "0          266   977  1243\n",
      "1          167  3489  3656\n",
      "All        433  4466  4899\n",
      "Accuracy: 0.7664829557052459\n",
      "Precision: 0.7388848720294048\n",
      "Recall: 0.7664829557052459\n",
      "F1 Score: 0.7216985402554134\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a Gradient Boosting Classifier model\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Fit the model to the data\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n",
    "# Get the feature importance\n",
    "feature_importance = gbc.feature_importances_\n",
    "\n",
    "# Rank the features from top to bottom\n",
    "feature_importance_df = pd.DataFrame({'Feature': features.columns, 'Importance': feature_importance})\n",
    "feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print the feature importance rankings\n",
    "print(\"Feature Importance:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Generate a confusion matrix and calculate the metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the confusion matrix and metrics\n",
    "print(\"Confusion matrix:\")\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small increment changes in random forrest so I will go with MinMax scaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'cleanedData/train_new.csv')\n",
    "df_test = pd.read_csv(r'cleanedData/test_new.csv')\n",
    "\n",
    "df = df_train\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "label = df[\"Y\"]\n",
    "df.drop('Y',axis=1,inplace=True)\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "df['Y'] = label\n",
    "df_train = df\n",
    "\n",
    "df = df_test\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "df_test = df\n",
    "\n",
    "df_train.to_csv(r'cleanedData/train_scalled.csv',index=False)\n",
    "df_test.to_csv(r'cleanedData/test_scalled.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "softec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
