{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'cleanedData/train_scalled.csv')\n",
    "df_test = pd.read_csv(r'cleanedData/test_scalled.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target variable from the features\n",
    "target = df['Y']\n",
    "features = df.drop('Y',axis=1)\n",
    "# features = df[labels]\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42, stratify = target)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=4, n_estimators=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=4, n_estimators=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=4, n_estimators=1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators= 1000, max_depth= 4)\n",
    "# Fit the classifier on the training set\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADIENT BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(max_depth=4, n_estimators=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(max_depth=4, n_estimators=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(max_depth=4, n_estimators=1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Gradient Boosting Classifier model\n",
    "gbc = GradientBoostingClassifier(n_estimators = 1000, max_depth=4)\n",
    "# Fit the model to the data\n",
    "gbc.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muham\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(dual=False, penalty=&#x27;l1&#x27;, tol=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(dual=False, penalty=&#x27;l1&#x27;, tol=0.001)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(dual=False, penalty='l1', tol=0.001)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the LinearSVC model with L1 penalty and squared hinge loss\n",
    "model_l1 = LinearSVC(penalty=\"l1\", loss=\"squared_hinge\", dual=False, tol=1e-3)\n",
    "# Train the model on the selected features\n",
    "model_l1.fit(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
      "Epoch 1/200\n",
      "90/90 [==============================] - 2s 7ms/step - loss: 0.6241 - accuracy: 0.7296 - val_loss: 0.5860 - val_accuracy: 0.7471 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
      "Epoch 2/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5746 - accuracy: 0.7472 - val_loss: 0.5674 - val_accuracy: 0.7471 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
      "Epoch 3/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5636 - accuracy: 0.7472 - val_loss: 0.5604 - val_accuracy: 0.7471 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
      "Epoch 4/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5573 - accuracy: 0.7472 - val_loss: 0.5547 - val_accuracy: 0.7471 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
      "Epoch 5/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5515 - accuracy: 0.7472 - val_loss: 0.5491 - val_accuracy: 0.7471 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
      "Epoch 6/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5456 - accuracy: 0.7472 - val_loss: 0.5435 - val_accuracy: 0.7471 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 9.900498298520688e-06.\n",
      "Epoch 7/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7472 - val_loss: 0.5383 - val_accuracy: 0.7473 - lr: 9.9005e-06\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 9.801986379898153e-06.\n",
      "Epoch 8/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5347 - accuracy: 0.7477 - val_loss: 0.5337 - val_accuracy: 0.7491 - lr: 9.8020e-06\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 9.70445489656413e-06.\n",
      "Epoch 9/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7509 - val_loss: 0.5297 - val_accuracy: 0.7508 - lr: 9.7045e-06\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 9.607893844076898e-06.\n",
      "Epoch 10/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5262 - accuracy: 0.7534 - val_loss: 0.5263 - val_accuracy: 0.7546 - lr: 9.6079e-06\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 9.51229412748944e-06.\n",
      "Epoch 11/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5229 - accuracy: 0.7549 - val_loss: 0.5235 - val_accuracy: 0.7573 - lr: 9.5123e-06\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 9.417644832865335e-06.\n",
      "Epoch 12/200\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5203 - accuracy: 0.7577 - val_loss: 0.5215 - val_accuracy: 0.7604 - lr: 9.4176e-06\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 9.323937774752267e-06.\n",
      "Epoch 13/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5181 - accuracy: 0.7597 - val_loss: 0.5195 - val_accuracy: 0.7616 - lr: 9.3239e-06\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 9.231162948708516e-06.\n",
      "Epoch 14/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5163 - accuracy: 0.7615 - val_loss: 0.5180 - val_accuracy: 0.7624 - lr: 9.2312e-06\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 9.139311259787064e-06.\n",
      "Epoch 15/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5149 - accuracy: 0.7635 - val_loss: 0.5167 - val_accuracy: 0.7628 - lr: 9.1393e-06\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 9.048373613040894e-06.\n",
      "Epoch 16/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5137 - accuracy: 0.7641 - val_loss: 0.5156 - val_accuracy: 0.7636 - lr: 9.0484e-06\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 8.958340913522989e-06.\n",
      "Epoch 17/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5128 - accuracy: 0.7638 - val_loss: 0.5147 - val_accuracy: 0.7636 - lr: 8.9583e-06\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 8.86920406628633e-06.\n",
      "Epoch 18/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5120 - accuracy: 0.7652 - val_loss: 0.5139 - val_accuracy: 0.7634 - lr: 8.8692e-06\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 8.780953976383898e-06.\n",
      "Epoch 19/200\n",
      "90/90 [==============================] - 0s 5ms/step - loss: 0.5111 - accuracy: 0.7665 - val_loss: 0.5132 - val_accuracy: 0.7646 - lr: 8.7810e-06\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 8.69358245836338e-06.\n",
      "Epoch 20/200\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5105 - accuracy: 0.7660 - val_loss: 0.5126 - val_accuracy: 0.7644 - lr: 8.6936e-06\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 8.607079507783055e-06.\n",
      "Epoch 21/200\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5101 - accuracy: 0.7652 - val_loss: 0.5120 - val_accuracy: 0.7634 - lr: 8.6071e-06\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 8.52143784868531e-06.\n",
      "Epoch 22/200\n",
      "90/90 [==============================] - 1s 6ms/step - loss: 0.5093 - accuracy: 0.7661 - val_loss: 0.5119 - val_accuracy: 0.7657 - lr: 8.5214e-06\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 8.436648386123125e-06.\n",
      "Epoch 23/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5090 - accuracy: 0.7652 - val_loss: 0.5113 - val_accuracy: 0.7636 - lr: 8.4366e-06\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 8.352702025149483e-06.\n",
      "Epoch 24/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5085 - accuracy: 0.7672 - val_loss: 0.5108 - val_accuracy: 0.7648 - lr: 8.3527e-06\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 8.269591489806771e-06.\n",
      "Epoch 25/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5083 - accuracy: 0.7672 - val_loss: 0.5105 - val_accuracy: 0.7640 - lr: 8.2696e-06\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 8.187307685147971e-06.\n",
      "Epoch 26/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5080 - accuracy: 0.7675 - val_loss: 0.5100 - val_accuracy: 0.7648 - lr: 8.1873e-06\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 8.105842425720766e-06.\n",
      "Epoch 27/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5078 - accuracy: 0.7671 - val_loss: 0.5097 - val_accuracy: 0.7648 - lr: 8.1058e-06\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 8.025188435567543e-06.\n",
      "Epoch 28/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5075 - accuracy: 0.7671 - val_loss: 0.5096 - val_accuracy: 0.7646 - lr: 8.0252e-06\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 7.945336619741283e-06.\n",
      "Epoch 29/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5071 - accuracy: 0.7680 - val_loss: 0.5092 - val_accuracy: 0.7653 - lr: 7.9453e-06\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 7.866278792789672e-06.\n",
      "Epoch 30/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5069 - accuracy: 0.7673 - val_loss: 0.5091 - val_accuracy: 0.7646 - lr: 7.8663e-06\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 7.788007678755093e-06.\n",
      "Epoch 31/200\n",
      "90/90 [==============================] - 1s 9ms/step - loss: 0.5068 - accuracy: 0.7679 - val_loss: 0.5089 - val_accuracy: 0.7644 - lr: 7.7880e-06\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 7.710516001679935e-06.\n",
      "Epoch 32/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5066 - accuracy: 0.7681 - val_loss: 0.5087 - val_accuracy: 0.7644 - lr: 7.7105e-06\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 7.63379557611188e-06.\n",
      "Epoch 33/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5065 - accuracy: 0.7686 - val_loss: 0.5087 - val_accuracy: 0.7661 - lr: 7.6338e-06\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 7.557838216598611e-06.\n",
      "Epoch 34/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5064 - accuracy: 0.7680 - val_loss: 0.5082 - val_accuracy: 0.7651 - lr: 7.5578e-06\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 7.482636647182517e-06.\n",
      "Epoch 35/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5061 - accuracy: 0.7677 - val_loss: 0.5082 - val_accuracy: 0.7661 - lr: 7.4826e-06\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 7.40818313715863e-06.\n",
      "Epoch 36/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5061 - accuracy: 0.7676 - val_loss: 0.5079 - val_accuracy: 0.7653 - lr: 7.4082e-06\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 7.334470410569338e-06.\n",
      "Epoch 37/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5058 - accuracy: 0.7687 - val_loss: 0.5078 - val_accuracy: 0.7648 - lr: 7.3345e-06\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 7.261491191457026e-06.\n",
      "Epoch 38/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5057 - accuracy: 0.7687 - val_loss: 0.5076 - val_accuracy: 0.7644 - lr: 7.2615e-06\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 7.189238203864079e-06.\n",
      "Epoch 39/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5056 - accuracy: 0.7684 - val_loss: 0.5075 - val_accuracy: 0.7659 - lr: 7.1892e-06\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 7.117704171832884e-06.\n",
      "Epoch 40/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5054 - accuracy: 0.7690 - val_loss: 0.5074 - val_accuracy: 0.7671 - lr: 7.1177e-06\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 7.046881819405826e-06.\n",
      "Epoch 41/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5054 - accuracy: 0.7688 - val_loss: 0.5075 - val_accuracy: 0.7667 - lr: 7.0469e-06\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 6.976764325372642e-06.\n",
      "Epoch 42/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5051 - accuracy: 0.7686 - val_loss: 0.5071 - val_accuracy: 0.7667 - lr: 6.9768e-06\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 6.907344413775718e-06.\n",
      "Epoch 43/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5051 - accuracy: 0.7704 - val_loss: 0.5071 - val_accuracy: 0.7677 - lr: 6.9073e-06\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 6.83861526340479e-06.\n",
      "Epoch 44/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5050 - accuracy: 0.7693 - val_loss: 0.5069 - val_accuracy: 0.7653 - lr: 6.8386e-06\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 6.770570053049596e-06.\n",
      "Epoch 45/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5049 - accuracy: 0.7689 - val_loss: 0.5068 - val_accuracy: 0.7663 - lr: 6.7706e-06\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 6.703201961499872e-06.\n",
      "Epoch 46/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5049 - accuracy: 0.7702 - val_loss: 0.5067 - val_accuracy: 0.7665 - lr: 6.7032e-06\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 6.636504167545354e-06.\n",
      "Epoch 47/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5047 - accuracy: 0.7692 - val_loss: 0.5066 - val_accuracy: 0.7673 - lr: 6.6365e-06\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 6.57046984997578e-06.\n",
      "Epoch 48/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5046 - accuracy: 0.7704 - val_loss: 0.5065 - val_accuracy: 0.7679 - lr: 6.5705e-06\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 6.505092642328236e-06.\n",
      "Epoch 49/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5046 - accuracy: 0.7697 - val_loss: 0.5065 - val_accuracy: 0.7665 - lr: 6.5051e-06\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 6.4403657233924605e-06.\n",
      "Epoch 50/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5045 - accuracy: 0.7687 - val_loss: 0.5063 - val_accuracy: 0.7677 - lr: 6.4404e-06\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 6.376283181452891e-06.\n",
      "Epoch 51/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5044 - accuracy: 0.7693 - val_loss: 0.5063 - val_accuracy: 0.7679 - lr: 6.3763e-06\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 6.312838195299264e-06.\n",
      "Epoch 52/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5043 - accuracy: 0.7700 - val_loss: 0.5062 - val_accuracy: 0.7681 - lr: 6.3128e-06\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 6.250024398468668e-06.\n",
      "Epoch 53/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5042 - accuracy: 0.7697 - val_loss: 0.5061 - val_accuracy: 0.7681 - lr: 6.2500e-06\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 6.187835424498189e-06.\n",
      "Epoch 54/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5041 - accuracy: 0.7697 - val_loss: 0.5061 - val_accuracy: 0.7683 - lr: 6.1878e-06\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 6.126265361672267e-06.\n",
      "Epoch 55/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5040 - accuracy: 0.7708 - val_loss: 0.5060 - val_accuracy: 0.7691 - lr: 6.1263e-06\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 6.0653078435279895e-06.\n",
      "Epoch 56/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5040 - accuracy: 0.7705 - val_loss: 0.5059 - val_accuracy: 0.7681 - lr: 6.0653e-06\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 6.004956958349794e-06.\n",
      "Epoch 57/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5039 - accuracy: 0.7712 - val_loss: 0.5059 - val_accuracy: 0.7679 - lr: 6.0050e-06\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 5.94520679442212e-06.\n",
      "Epoch 58/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5038 - accuracy: 0.7701 - val_loss: 0.5058 - val_accuracy: 0.7689 - lr: 5.9452e-06\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 5.886050985282054e-06.\n",
      "Epoch 59/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5038 - accuracy: 0.7707 - val_loss: 0.5057 - val_accuracy: 0.7687 - lr: 5.8861e-06\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 5.8274836192140356e-06.\n",
      "Epoch 60/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5036 - accuracy: 0.7714 - val_loss: 0.5057 - val_accuracy: 0.7681 - lr: 5.8275e-06\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 5.769499239249853e-06.\n",
      "Epoch 61/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5037 - accuracy: 0.7704 - val_loss: 0.5056 - val_accuracy: 0.7675 - lr: 5.7695e-06\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 5.712091933673946e-06.\n",
      "Epoch 62/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5035 - accuracy: 0.7713 - val_loss: 0.5056 - val_accuracy: 0.7687 - lr: 5.7121e-06\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 5.655255790770752e-06.\n",
      "Epoch 63/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5035 - accuracy: 0.7708 - val_loss: 0.5055 - val_accuracy: 0.7691 - lr: 5.6553e-06\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 5.59898489882471e-06.\n",
      "Epoch 64/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5035 - accuracy: 0.7704 - val_loss: 0.5054 - val_accuracy: 0.7683 - lr: 5.5990e-06\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 5.5432742556149606e-06.\n",
      "Epoch 65/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5034 - accuracy: 0.7713 - val_loss: 0.5053 - val_accuracy: 0.7685 - lr: 5.5433e-06\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 5.488117949425941e-06.\n",
      "Epoch 66/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5033 - accuracy: 0.7712 - val_loss: 0.5053 - val_accuracy: 0.7683 - lr: 5.4881e-06\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 5.433510068542091e-06.\n",
      "Epoch 67/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5032 - accuracy: 0.7719 - val_loss: 0.5052 - val_accuracy: 0.7685 - lr: 5.4335e-06\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 5.37944561074255e-06.\n",
      "Epoch 68/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5032 - accuracy: 0.7722 - val_loss: 0.5052 - val_accuracy: 0.7683 - lr: 5.3794e-06\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 5.325919119059108e-06.\n",
      "Epoch 69/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5031 - accuracy: 0.7714 - val_loss: 0.5051 - val_accuracy: 0.7683 - lr: 5.3259e-06\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 5.272925591270905e-06.\n",
      "Epoch 70/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5031 - accuracy: 0.7713 - val_loss: 0.5051 - val_accuracy: 0.7681 - lr: 5.2729e-06\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 5.220459115662379e-06.\n",
      "Epoch 71/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5030 - accuracy: 0.7712 - val_loss: 0.5051 - val_accuracy: 0.7683 - lr: 5.2205e-06\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 5.168514690012671e-06.\n",
      "Epoch 72/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5030 - accuracy: 0.7715 - val_loss: 0.5050 - val_accuracy: 0.7687 - lr: 5.1685e-06\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 5.117087312100921e-06.\n",
      "Epoch 73/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5029 - accuracy: 0.7704 - val_loss: 0.5051 - val_accuracy: 0.7695 - lr: 5.1171e-06\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 5.066171524958918e-06.\n",
      "Epoch 74/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5030 - accuracy: 0.7709 - val_loss: 0.5050 - val_accuracy: 0.7697 - lr: 5.0662e-06\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 5.0157623263658024e-06.\n",
      "Epoch 75/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5028 - accuracy: 0.7713 - val_loss: 0.5049 - val_accuracy: 0.7693 - lr: 5.0158e-06\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 4.965854714100715e-06.\n",
      "Epoch 76/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5027 - accuracy: 0.7710 - val_loss: 0.5048 - val_accuracy: 0.7693 - lr: 4.9659e-06\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 4.916443685942795e-06.\n",
      "Epoch 77/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5027 - accuracy: 0.7717 - val_loss: 0.5048 - val_accuracy: 0.7689 - lr: 4.9164e-06\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 4.867524239671184e-06.\n",
      "Epoch 78/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5026 - accuracy: 0.7715 - val_loss: 0.5048 - val_accuracy: 0.7697 - lr: 4.8675e-06\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 4.819091373065021e-06.\n",
      "Epoch 79/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5026 - accuracy: 0.7716 - val_loss: 0.5047 - val_accuracy: 0.7702 - lr: 4.8191e-06\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 4.771140538650798e-06.\n",
      "Epoch 80/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5026 - accuracy: 0.7711 - val_loss: 0.5047 - val_accuracy: 0.7700 - lr: 4.7711e-06\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 4.723666734207654e-06.\n",
      "Epoch 81/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5025 - accuracy: 0.7712 - val_loss: 0.5046 - val_accuracy: 0.7700 - lr: 4.7237e-06\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 4.676665412262082e-06.\n",
      "Epoch 82/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5025 - accuracy: 0.7714 - val_loss: 0.5046 - val_accuracy: 0.7697 - lr: 4.6767e-06\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 4.630132025340572e-06.\n",
      "Epoch 83/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5025 - accuracy: 0.7708 - val_loss: 0.5046 - val_accuracy: 0.7697 - lr: 4.6301e-06\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 4.584061571222264e-06.\n",
      "Epoch 84/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5024 - accuracy: 0.7714 - val_loss: 0.5046 - val_accuracy: 0.7702 - lr: 4.5841e-06\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 4.53844950243365e-06.\n",
      "Epoch 85/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5023 - accuracy: 0.7713 - val_loss: 0.5045 - val_accuracy: 0.7700 - lr: 4.5384e-06\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 4.493291271501221e-06.\n",
      "Epoch 86/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5023 - accuracy: 0.7717 - val_loss: 0.5045 - val_accuracy: 0.7706 - lr: 4.4933e-06\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 4.448582330951467e-06.\n",
      "Epoch 87/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5023 - accuracy: 0.7715 - val_loss: 0.5044 - val_accuracy: 0.7700 - lr: 4.4486e-06\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 4.4043181333108805e-06.\n",
      "Epoch 88/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5022 - accuracy: 0.7712 - val_loss: 0.5044 - val_accuracy: 0.7697 - lr: 4.4043e-06\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 4.360494585853303e-06.\n",
      "Epoch 89/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5022 - accuracy: 0.7717 - val_loss: 0.5044 - val_accuracy: 0.7706 - lr: 4.3605e-06\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 4.317107141105225e-06.\n",
      "Epoch 90/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5021 - accuracy: 0.7720 - val_loss: 0.5043 - val_accuracy: 0.7706 - lr: 4.3171e-06\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 4.274151251593139e-06.\n",
      "Epoch 91/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5021 - accuracy: 0.7715 - val_loss: 0.5043 - val_accuracy: 0.7706 - lr: 4.2742e-06\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 4.231622824590886e-06.\n",
      "Epoch 92/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5020 - accuracy: 0.7709 - val_loss: 0.5043 - val_accuracy: 0.7700 - lr: 4.2316e-06\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 4.189517312624957e-06.\n",
      "Epoch 93/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5021 - accuracy: 0.7716 - val_loss: 0.5043 - val_accuracy: 0.7710 - lr: 4.1895e-06\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 4.147831077716546e-06.\n",
      "Epoch 94/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5020 - accuracy: 0.7715 - val_loss: 0.5042 - val_accuracy: 0.7708 - lr: 4.1478e-06\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 4.106559572392143e-06.\n",
      "Epoch 95/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5019 - accuracy: 0.7722 - val_loss: 0.5042 - val_accuracy: 0.7708 - lr: 4.1066e-06\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 4.065698703925591e-06.\n",
      "Epoch 96/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5019 - accuracy: 0.7715 - val_loss: 0.5042 - val_accuracy: 0.7695 - lr: 4.0657e-06\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 4.025244379590731e-06.\n",
      "Epoch 97/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5019 - accuracy: 0.7715 - val_loss: 0.5042 - val_accuracy: 0.7702 - lr: 4.0252e-06\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.985192506661406e-06.\n",
      "Epoch 98/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5018 - accuracy: 0.7715 - val_loss: 0.5042 - val_accuracy: 0.7704 - lr: 3.9852e-06\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 3.945538992411457e-06.\n",
      "Epoch 99/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5018 - accuracy: 0.7718 - val_loss: 0.5041 - val_accuracy: 0.7702 - lr: 3.9455e-06\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 3.906280198862078e-06.\n",
      "Epoch 100/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5018 - accuracy: 0.7715 - val_loss: 0.5040 - val_accuracy: 0.7714 - lr: 3.9063e-06\n",
      "\n",
      "Epoch 101: LearningRateScheduler setting learning rate to 3.86741203328711e-06.\n",
      "Epoch 101/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5017 - accuracy: 0.7721 - val_loss: 0.5040 - val_accuracy: 0.7718 - lr: 3.8674e-06\n",
      "\n",
      "Epoch 102: LearningRateScheduler setting learning rate to 3.828930857707746e-06.\n",
      "Epoch 102/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5017 - accuracy: 0.7718 - val_loss: 0.5040 - val_accuracy: 0.7704 - lr: 3.8289e-06\n",
      "\n",
      "Epoch 103: LearningRateScheduler setting learning rate to 3.790832352024154e-06.\n",
      "Epoch 103/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5017 - accuracy: 0.7720 - val_loss: 0.5040 - val_accuracy: 0.7718 - lr: 3.7908e-06\n",
      "\n",
      "Epoch 104: LearningRateScheduler setting learning rate to 3.753112878257525e-06.\n",
      "Epoch 104/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5016 - accuracy: 0.7721 - val_loss: 0.5040 - val_accuracy: 0.7710 - lr: 3.7531e-06\n",
      "\n",
      "Epoch 105: LearningRateScheduler setting learning rate to 3.7157687984290533e-06.\n",
      "Epoch 105/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5016 - accuracy: 0.7718 - val_loss: 0.5039 - val_accuracy: 0.7716 - lr: 3.7158e-06\n",
      "\n",
      "Epoch 106: LearningRateScheduler setting learning rate to 3.6787962471862556e-06.\n",
      "Epoch 106/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5016 - accuracy: 0.7717 - val_loss: 0.5039 - val_accuracy: 0.7714 - lr: 3.6788e-06\n",
      "\n",
      "Epoch 107: LearningRateScheduler setting learning rate to 3.642191586550325e-06.\n",
      "Epoch 107/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5016 - accuracy: 0.7719 - val_loss: 0.5039 - val_accuracy: 0.7722 - lr: 3.6422e-06\n",
      "\n",
      "Epoch 108: LearningRateScheduler setting learning rate to 3.6059511785424547e-06.\n",
      "Epoch 108/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5015 - accuracy: 0.7719 - val_loss: 0.5039 - val_accuracy: 0.7708 - lr: 3.6060e-06\n",
      "\n",
      "Epoch 109: LearningRateScheduler setting learning rate to 3.5700713851838373e-06.\n",
      "Epoch 109/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5015 - accuracy: 0.7715 - val_loss: 0.5039 - val_accuracy: 0.7712 - lr: 3.5701e-06\n",
      "\n",
      "Epoch 110: LearningRateScheduler setting learning rate to 3.5345485684956657e-06.\n",
      "Epoch 110/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5015 - accuracy: 0.7713 - val_loss: 0.5038 - val_accuracy: 0.7710 - lr: 3.5345e-06\n",
      "\n",
      "Epoch 111: LearningRateScheduler setting learning rate to 3.4993793178728083e-06.\n",
      "Epoch 111/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5014 - accuracy: 0.7721 - val_loss: 0.5038 - val_accuracy: 0.7708 - lr: 3.4994e-06\n",
      "\n",
      "Epoch 112: LearningRateScheduler setting learning rate to 3.464559995336458e-06.\n",
      "Epoch 112/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5014 - accuracy: 0.7726 - val_loss: 0.5038 - val_accuracy: 0.7708 - lr: 3.4646e-06\n",
      "\n",
      "Epoch 113: LearningRateScheduler setting learning rate to 3.430086962907808e-06.\n",
      "Epoch 113/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5015 - accuracy: 0.7712 - val_loss: 0.5038 - val_accuracy: 0.7716 - lr: 3.4301e-06\n",
      "\n",
      "Epoch 114: LearningRateScheduler setting learning rate to 3.3959570373554016e-06.\n",
      "Epoch 114/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5014 - accuracy: 0.7724 - val_loss: 0.5037 - val_accuracy: 0.7714 - lr: 3.3960e-06\n",
      "\n",
      "Epoch 115: LearningRateScheduler setting learning rate to 3.3621668080741074e-06.\n",
      "Epoch 115/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5013 - accuracy: 0.7724 - val_loss: 0.5038 - val_accuracy: 0.7702 - lr: 3.3622e-06\n",
      "\n",
      "Epoch 116: LearningRateScheduler setting learning rate to 3.3287126370851183e-06.\n",
      "Epoch 116/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5013 - accuracy: 0.7718 - val_loss: 0.5037 - val_accuracy: 0.7718 - lr: 3.3287e-06\n",
      "\n",
      "Epoch 117: LearningRateScheduler setting learning rate to 3.295591341156978e-06.\n",
      "Epoch 117/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5013 - accuracy: 0.7722 - val_loss: 0.5037 - val_accuracy: 0.7718 - lr: 3.2956e-06\n",
      "\n",
      "Epoch 118: LearningRateScheduler setting learning rate to 3.2627997370582307e-06.\n",
      "Epoch 118/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5012 - accuracy: 0.7718 - val_loss: 0.5037 - val_accuracy: 0.7720 - lr: 3.2628e-06\n",
      "\n",
      "Epoch 119: LearningRateScheduler setting learning rate to 3.2303344141837442e-06.\n",
      "Epoch 119/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5012 - accuracy: 0.7721 - val_loss: 0.5037 - val_accuracy: 0.7716 - lr: 3.2303e-06\n",
      "\n",
      "Epoch 120: LearningRateScheduler setting learning rate to 3.198191961928387e-06.\n",
      "Epoch 120/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5012 - accuracy: 0.7722 - val_loss: 0.5036 - val_accuracy: 0.7714 - lr: 3.1982e-06\n",
      "\n",
      "Epoch 121: LearningRateScheduler setting learning rate to 3.1663694244343787e-06.\n",
      "Epoch 121/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5012 - accuracy: 0.7722 - val_loss: 0.5036 - val_accuracy: 0.7712 - lr: 3.1664e-06\n",
      "\n",
      "Epoch 122: LearningRateScheduler setting learning rate to 3.1348636184702627e-06.\n",
      "Epoch 122/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5012 - accuracy: 0.7720 - val_loss: 0.5036 - val_accuracy: 0.7716 - lr: 3.1349e-06\n",
      "\n",
      "Epoch 123: LearningRateScheduler setting learning rate to 3.1036711334309075e-06.\n",
      "Epoch 123/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5011 - accuracy: 0.7728 - val_loss: 0.5036 - val_accuracy: 0.7714 - lr: 3.1037e-06\n",
      "\n",
      "Epoch 124: LearningRateScheduler setting learning rate to 3.0727890134585323e-06.\n",
      "Epoch 124/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5012 - accuracy: 0.7719 - val_loss: 0.5036 - val_accuracy: 0.7712 - lr: 3.0728e-06\n",
      "\n",
      "Epoch 125: LearningRateScheduler setting learning rate to 3.0422143026953563e-06.\n",
      "Epoch 125/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5011 - accuracy: 0.7725 - val_loss: 0.5035 - val_accuracy: 0.7716 - lr: 3.0422e-06\n",
      "\n",
      "Epoch 126: LearningRateScheduler setting learning rate to 3.0119438179099234e-06.\n",
      "Epoch 126/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5011 - accuracy: 0.7714 - val_loss: 0.5035 - val_accuracy: 0.7712 - lr: 3.0119e-06\n",
      "\n",
      "Epoch 127: LearningRateScheduler setting learning rate to 2.9819746032444527e-06.\n",
      "Epoch 127/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5010 - accuracy: 0.7720 - val_loss: 0.5035 - val_accuracy: 0.7718 - lr: 2.9820e-06\n",
      "\n",
      "Epoch 128: LearningRateScheduler setting learning rate to 2.952303475467488e-06.\n",
      "Epoch 128/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5010 - accuracy: 0.7721 - val_loss: 0.5035 - val_accuracy: 0.7706 - lr: 2.9523e-06\n",
      "\n",
      "Epoch 129: LearningRateScheduler setting learning rate to 2.922927478721249e-06.\n",
      "Epoch 129/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5010 - accuracy: 0.7722 - val_loss: 0.5034 - val_accuracy: 0.7716 - lr: 2.9229e-06\n",
      "\n",
      "Epoch 130: LearningRateScheduler setting learning rate to 2.8938438845216297e-06.\n",
      "Epoch 130/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5010 - accuracy: 0.7721 - val_loss: 0.5035 - val_accuracy: 0.7710 - lr: 2.8938e-06\n",
      "\n",
      "Epoch 131: LearningRateScheduler setting learning rate to 2.8650497370108496e-06.\n",
      "Epoch 131/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5009 - accuracy: 0.7721 - val_loss: 0.5034 - val_accuracy: 0.7714 - lr: 2.8650e-06\n",
      "\n",
      "Epoch 132: LearningRateScheduler setting learning rate to 2.836542080331128e-06.\n",
      "Epoch 132/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5009 - accuracy: 0.7727 - val_loss: 0.5034 - val_accuracy: 0.7712 - lr: 2.8365e-06\n",
      "\n",
      "Epoch 133: LearningRateScheduler setting learning rate to 2.8083179586246843e-06.\n",
      "Epoch 133/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5010 - accuracy: 0.7719 - val_loss: 0.5034 - val_accuracy: 0.7708 - lr: 2.8083e-06\n",
      "\n",
      "Epoch 134: LearningRateScheduler setting learning rate to 2.780374643407413e-06.\n",
      "Epoch 134/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5009 - accuracy: 0.7716 - val_loss: 0.5034 - val_accuracy: 0.7708 - lr: 2.7804e-06\n",
      "\n",
      "Epoch 135: LearningRateScheduler setting learning rate to 2.7527094061952084e-06.\n",
      "Epoch 135/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5009 - accuracy: 0.7720 - val_loss: 0.5034 - val_accuracy: 0.7708 - lr: 2.7527e-06\n",
      "\n",
      "Epoch 136: LearningRateScheduler setting learning rate to 2.725319518503966e-06.\n",
      "Epoch 136/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5008 - accuracy: 0.7724 - val_loss: 0.5034 - val_accuracy: 0.7712 - lr: 2.7253e-06\n",
      "\n",
      "Epoch 137: LearningRateScheduler setting learning rate to 2.6982022518495796e-06.\n",
      "Epoch 137/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5008 - accuracy: 0.7722 - val_loss: 0.5034 - val_accuracy: 0.7712 - lr: 2.6982e-06\n",
      "\n",
      "Epoch 138: LearningRateScheduler setting learning rate to 2.671354650374269e-06.\n",
      "Epoch 138/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5008 - accuracy: 0.7719 - val_loss: 0.5033 - val_accuracy: 0.7712 - lr: 2.6714e-06\n",
      "\n",
      "Epoch 139: LearningRateScheduler setting learning rate to 2.6447742129676044e-06.\n",
      "Epoch 139/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5008 - accuracy: 0.7725 - val_loss: 0.5033 - val_accuracy: 0.7710 - lr: 2.6448e-06\n",
      "\n",
      "Epoch 140: LearningRateScheduler setting learning rate to 2.61845821114548e-06.\n",
      "Epoch 140/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5008 - accuracy: 0.7720 - val_loss: 0.5033 - val_accuracy: 0.7712 - lr: 2.6185e-06\n",
      "\n",
      "Epoch 141: LearningRateScheduler setting learning rate to 2.5924041437974665e-06.\n",
      "Epoch 141/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5008 - accuracy: 0.7722 - val_loss: 0.5033 - val_accuracy: 0.7708 - lr: 2.5924e-06\n",
      "\n",
      "Epoch 142: LearningRateScheduler setting learning rate to 2.566609282439458e-06.\n",
      "Epoch 142/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5008 - accuracy: 0.7726 - val_loss: 0.5033 - val_accuracy: 0.7708 - lr: 2.5666e-06\n",
      "\n",
      "Epoch 143: LearningRateScheduler setting learning rate to 2.5410711259610252e-06.\n",
      "Epoch 143/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5007 - accuracy: 0.7718 - val_loss: 0.5033 - val_accuracy: 0.7708 - lr: 2.5411e-06\n",
      "\n",
      "Epoch 144: LearningRateScheduler setting learning rate to 2.5157869458780624e-06.\n",
      "Epoch 144/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5007 - accuracy: 0.7718 - val_loss: 0.5032 - val_accuracy: 0.7710 - lr: 2.5158e-06\n",
      "\n",
      "Epoch 145: LearningRateScheduler setting learning rate to 2.490754468453815e-06.\n",
      "Epoch 145/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5007 - accuracy: 0.7718 - val_loss: 0.5032 - val_accuracy: 0.7706 - lr: 2.4908e-06\n",
      "\n",
      "Epoch 146: LearningRateScheduler setting learning rate to 2.4659709652041784e-06.\n",
      "Epoch 146/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5007 - accuracy: 0.7720 - val_loss: 0.5032 - val_accuracy: 0.7706 - lr: 2.4660e-06\n",
      "\n",
      "Epoch 147: LearningRateScheduler setting learning rate to 2.4414341623923974e-06.\n",
      "Epoch 147/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5006 - accuracy: 0.7720 - val_loss: 0.5032 - val_accuracy: 0.7706 - lr: 2.4414e-06\n",
      "\n",
      "Epoch 148: LearningRateScheduler setting learning rate to 2.4171415589080425e-06.\n",
      "Epoch 148/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5006 - accuracy: 0.7717 - val_loss: 0.5032 - val_accuracy: 0.7706 - lr: 2.4171e-06\n",
      "\n",
      "Epoch 149: LearningRateScheduler setting learning rate to 2.3930906536406837e-06.\n",
      "Epoch 149/200\n",
      "90/90 [==============================] - 1s 7ms/step - loss: 0.5007 - accuracy: 0.7726 - val_loss: 0.5032 - val_accuracy: 0.7718 - lr: 2.3931e-06\n",
      "\n",
      "Epoch 150: LearningRateScheduler setting learning rate to 2.3692789454798913e-06.\n",
      "Epoch 150/200\n",
      "90/90 [==============================] - 1s 8ms/step - loss: 0.5006 - accuracy: 0.7718 - val_loss: 0.5032 - val_accuracy: 0.7708 - lr: 2.3693e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x279b1aaeca0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "y = y_train\n",
    "X = X_train\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X.shape[1], activation='tanh'))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dense(16, activation='tanh'))\n",
    "model.add(Dense(8, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.00001), metrics=['accuracy'])\n",
    "def schedule(epoch, lr):    \n",
    "    if epoch > 5:\n",
    "        return lr * tf.math.exp(-0.01)\n",
    "    else:\n",
    "        return lr\n",
    "model_learningRate_schedular = tf.keras.callbacks.LearningRateScheduler(schedule, verbose=1)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0.001,\n",
    "    patience=50,\n",
    "    mode=\"auto\",\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "my_callbacks = [model_learningRate_schedular, early_stopping]\n",
    "# Fit the model to the data\n",
    "model.fit(X, y, epochs=200, batch_size=128, validation_data=(X_test,y_test),callbacks=my_callbacks)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=126)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=126)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=126)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=126)\n",
    "neigh.fit(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSAMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting(a, b, c, d, e):\n",
    "    ensemble_pred = []\n",
    "    t = 0\n",
    "    for i in range(len(a)):\n",
    "        count = {0: 0, 1: 0} \n",
    "        \n",
    "        count[a[i]] += 1\n",
    "        count[b[i]] += 1\n",
    "        count[c[i]] += 1\n",
    "        count[e[i]] += 1\n",
    "        \n",
    "        count[d[i][0]] += 1\n",
    "        \n",
    "        majority_label = max(count, key=count.get)\n",
    "        ensemble_pred.append(majority_label)\n",
    "        \n",
    "    return ensemble_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds1 = rf.predict(X_test)\n",
    "preds2 = gbc.predict(X_test)\n",
    "preds3 = model_l1.predict(X_test)\n",
    "preds4 = model.predict(X_test)\n",
    "preds4 = preds4 >= 0.5\n",
    "preds4 = np.multiply(preds4, 1)\n",
    "preds5 = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = majority_voting(preds1, preds2, preds3, preds4, preds5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "Predicted    0     1   All\n",
      "True                      \n",
      "0          199  1040  1239\n",
      "1           91  3569  3660\n",
      "All        290  4609  4899\n",
      "Accuracy: 0.7691365584813227\n",
      "Precision: 0.7520612169384308\n",
      "Recall: 0.7691365584813227\n",
      "F1 Score: 0.7107395229109342\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix and calculate the metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the confusion matrix and metrics\n",
    "print(\"Confusion matrix:\")\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit with remaining data and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 2.3692789454798913e-06.\n",
      "Epoch 1/200\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.5245 - accuracy: 0.7574"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muham\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 12ms/step - loss: 0.5041 - accuracy: 0.7712 - val_loss: 0.5040 - val_accuracy: 0.7714 - lr: 2.3693e-06\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 2.3692789454798913e-06.\n",
      "Epoch 2/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5040 - accuracy: 0.7708 - val_loss: 0.5039 - val_accuracy: 0.7710 - lr: 2.3693e-06\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 2.3692789454798913e-06.\n",
      "Epoch 3/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5039 - accuracy: 0.7706 - val_loss: 0.5039 - val_accuracy: 0.7710 - lr: 2.3693e-06\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 2.3692789454798913e-06.\n",
      "Epoch 4/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5039 - accuracy: 0.7712 - val_loss: 0.5038 - val_accuracy: 0.7714 - lr: 2.3693e-06\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 2.3692789454798913e-06.\n",
      "Epoch 5/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5038 - accuracy: 0.7708 - val_loss: 0.5037 - val_accuracy: 0.7706 - lr: 2.3693e-06\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 2.3692789454798913e-06.\n",
      "Epoch 6/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5037 - accuracy: 0.7706 - val_loss: 0.5037 - val_accuracy: 0.7712 - lr: 2.3693e-06\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 2.3457041606889106e-06.\n",
      "Epoch 7/200\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.5037 - accuracy: 0.7712 - val_loss: 0.5036 - val_accuracy: 0.7712 - lr: 2.3457e-06\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 2.3223640255309874e-06.\n",
      "Epoch 8/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5036 - accuracy: 0.7708 - val_loss: 0.5036 - val_accuracy: 0.7710 - lr: 2.3224e-06\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 2.2992560388956917e-06.\n",
      "Epoch 9/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5036 - accuracy: 0.7708 - val_loss: 0.5035 - val_accuracy: 0.7708 - lr: 2.2993e-06\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 2.2763781544199446e-06.\n",
      "Epoch 10/200\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.5035 - accuracy: 0.7704 - val_loss: 0.5035 - val_accuracy: 0.7704 - lr: 2.2764e-06\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 2.253727870993316e-06.\n",
      "Epoch 11/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5034 - accuracy: 0.7706 - val_loss: 0.5034 - val_accuracy: 0.7712 - lr: 2.2537e-06\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 2.231302914879052e-06.\n",
      "Epoch 12/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5035 - accuracy: 0.7708 - val_loss: 0.5034 - val_accuracy: 0.7710 - lr: 2.2313e-06\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 2.2091010123403976e-06.\n",
      "Epoch 13/200\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.5034 - accuracy: 0.7702 - val_loss: 0.5033 - val_accuracy: 0.7704 - lr: 2.2091e-06\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 2.187120117014274e-06.\n",
      "Epoch 14/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5033 - accuracy: 0.7710 - val_loss: 0.5033 - val_accuracy: 0.7706 - lr: 2.1871e-06\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 2.165357955163927e-06.\n",
      "Epoch 15/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5034 - accuracy: 0.7710 - val_loss: 0.5032 - val_accuracy: 0.7710 - lr: 2.1654e-06\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 2.1438122530526016e-06.\n",
      "Epoch 16/200\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.5032 - accuracy: 0.7706 - val_loss: 0.5032 - val_accuracy: 0.7708 - lr: 2.1438e-06\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 2.1224809643172193e-06.\n",
      "Epoch 17/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5033 - accuracy: 0.7708 - val_loss: 0.5031 - val_accuracy: 0.7708 - lr: 2.1225e-06\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 2.101362042594701e-06.\n",
      "Epoch 18/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5032 - accuracy: 0.7706 - val_loss: 0.5031 - val_accuracy: 0.7706 - lr: 2.1014e-06\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 2.0804532141482923e-06.\n",
      "Epoch 19/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5031 - accuracy: 0.7706 - val_loss: 0.5031 - val_accuracy: 0.7706 - lr: 2.0805e-06\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 2.059752432614914e-06.\n",
      "Epoch 20/200\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.5031 - accuracy: 0.7712 - val_loss: 0.5030 - val_accuracy: 0.7706 - lr: 2.0598e-06\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 2.0392576516314875e-06.\n",
      "Epoch 21/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5031 - accuracy: 0.7710 - val_loss: 0.5030 - val_accuracy: 0.7710 - lr: 2.0393e-06\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 2.018966597461258e-06.\n",
      "Epoch 22/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5030 - accuracy: 0.7710 - val_loss: 0.5030 - val_accuracy: 0.7710 - lr: 2.0190e-06\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 1.998877451114822e-06.\n",
      "Epoch 23/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5030 - accuracy: 0.7712 - val_loss: 0.5029 - val_accuracy: 0.7712 - lr: 1.9989e-06\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 1.9789883936027763e-06.\n",
      "Epoch 24/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5030 - accuracy: 0.7718 - val_loss: 0.5029 - val_accuracy: 0.7710 - lr: 1.9790e-06\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 1.959297151188366e-06.\n",
      "Epoch 25/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5029 - accuracy: 0.7712 - val_loss: 0.5029 - val_accuracy: 0.7712 - lr: 1.9593e-06\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 1.939801904882188e-06.\n",
      "Epoch 26/200\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.5029 - accuracy: 0.7712 - val_loss: 0.5028 - val_accuracy: 0.7714 - lr: 1.9398e-06\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 1.920500608321163e-06.\n",
      "Epoch 27/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5028 - accuracy: 0.7714 - val_loss: 0.5028 - val_accuracy: 0.7714 - lr: 1.9205e-06\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 1.9013913288290496e-06.\n",
      "Epoch 28/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5028 - accuracy: 0.7712 - val_loss: 0.5028 - val_accuracy: 0.7710 - lr: 1.9014e-06\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 1.8824721337296069e-06.\n",
      "Epoch 29/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5028 - accuracy: 0.7712 - val_loss: 0.5027 - val_accuracy: 0.7712 - lr: 1.8825e-06\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 1.8637412040334311e-06.\n",
      "Epoch 30/200\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.5028 - accuracy: 0.7712 - val_loss: 0.5027 - val_accuracy: 0.7710 - lr: 1.8637e-06\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 1.8451967207511188e-06.\n",
      "Epoch 31/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5028 - accuracy: 0.7714 - val_loss: 0.5027 - val_accuracy: 0.7714 - lr: 1.8452e-06\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 1.8268367512064287e-06.\n",
      "Epoch 32/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5027 - accuracy: 0.7710 - val_loss: 0.5027 - val_accuracy: 0.7706 - lr: 1.8268e-06\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 1.8086594764099573e-06.\n",
      "Epoch 33/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5027 - accuracy: 0.7708 - val_loss: 0.5026 - val_accuracy: 0.7710 - lr: 1.8087e-06\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 1.790663077372301e-06.\n",
      "Epoch 34/200\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.5027 - accuracy: 0.7710 - val_loss: 0.5026 - val_accuracy: 0.7704 - lr: 1.7907e-06\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 1.772845735104056e-06.\n",
      "Epoch 35/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5026 - accuracy: 0.7704 - val_loss: 0.5026 - val_accuracy: 0.7702 - lr: 1.7728e-06\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 1.7552056306158192e-06.\n",
      "Epoch 36/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5026 - accuracy: 0.7706 - val_loss: 0.5026 - val_accuracy: 0.7712 - lr: 1.7552e-06\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 1.7377410586050246e-06.\n",
      "Epoch 37/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5026 - accuracy: 0.7716 - val_loss: 0.5025 - val_accuracy: 0.7710 - lr: 1.7377e-06\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 1.7204502000822686e-06.\n",
      "Epoch 38/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5026 - accuracy: 0.7712 - val_loss: 0.5025 - val_accuracy: 0.7712 - lr: 1.7205e-06\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 1.703331463431823e-06.\n",
      "Epoch 39/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5025 - accuracy: 0.7712 - val_loss: 0.5025 - val_accuracy: 0.7710 - lr: 1.7033e-06\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 1.6863830296642845e-06.\n",
      "Epoch 40/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5025 - accuracy: 0.7710 - val_loss: 0.5025 - val_accuracy: 0.7710 - lr: 1.6864e-06\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 1.6696031934770872e-06.\n",
      "Epoch 41/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5025 - accuracy: 0.7708 - val_loss: 0.5025 - val_accuracy: 0.7710 - lr: 1.6696e-06\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 1.6529903632545029e-06.\n",
      "Epoch 42/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5025 - accuracy: 0.7710 - val_loss: 0.5024 - val_accuracy: 0.7710 - lr: 1.6530e-06\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 1.6365428336939658e-06.\n",
      "Epoch 43/200\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.5025 - accuracy: 0.7710 - val_loss: 0.5024 - val_accuracy: 0.7708 - lr: 1.6365e-06\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 1.6202590131797479e-06.\n",
      "Epoch 44/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5024 - accuracy: 0.7710 - val_loss: 0.5024 - val_accuracy: 0.7708 - lr: 1.6203e-06\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 1.6041371964092832e-06.\n",
      "Epoch 45/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5024 - accuracy: 0.7710 - val_loss: 0.5024 - val_accuracy: 0.7710 - lr: 1.6041e-06\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 1.5881757917668438e-06.\n",
      "Epoch 46/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5024 - accuracy: 0.7710 - val_loss: 0.5023 - val_accuracy: 0.7708 - lr: 1.5882e-06\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 1.5723732076367014e-06.\n",
      "Epoch 47/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5024 - accuracy: 0.7706 - val_loss: 0.5023 - val_accuracy: 0.7708 - lr: 1.5724e-06\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 1.556727852403128e-06.\n",
      "Epoch 48/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5024 - accuracy: 0.7706 - val_loss: 0.5023 - val_accuracy: 0.7710 - lr: 1.5567e-06\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 1.5412381344503956e-06.\n",
      "Epoch 49/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5023 - accuracy: 0.7710 - val_loss: 0.5023 - val_accuracy: 0.7710 - lr: 1.5412e-06\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 1.5259025758496136e-06.\n",
      "Epoch 50/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5023 - accuracy: 0.7714 - val_loss: 0.5023 - val_accuracy: 0.7712 - lr: 1.5259e-06\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 1.510719584985054e-06.\n",
      "Epoch 51/200\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.5023 - accuracy: 0.7706 - val_loss: 0.5023 - val_accuracy: 0.7708 - lr: 1.5107e-06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=126)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=126)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=126)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_test, y_test)\n",
    "gbc.fit(X_test,y_test)\n",
    "model_l1.fit(X_test,y_test)\n",
    "model.fit(X_test,y_test,epochs=200, batch_size=128, validation_data=(X_test,y_test),callbacks=my_callbacks)\n",
    "neigh.fit(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds1 = rf.predict(X_test)\n",
    "preds2 = gbc.predict(X_test)\n",
    "preds3 = model_l1.predict(X_test)\n",
    "preds4 = model.predict(X_test)\n",
    "preds4 = preds4 >= 0.5\n",
    "preds4 = np.multiply(preds4, 1)\n",
    "preds5 = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = majority_voting(preds1, preds2, preds3, preds4, preds5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "Predicted    0     1   All\n",
      "True                      \n",
      "0          249   990  1239\n",
      "1           55  3605  3660\n",
      "All        304  4595  4899\n",
      "Accuracy: 0.7866911614615227\n",
      "Precision: 0.793281494393612\n",
      "Recall: 0.7866911614615227\n",
      "F1 Score: 0.7341427719588748\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix and calculate the metrics\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the confusion matrix and metrics\n",
    "print(\"Confusion matrix:\")\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds1 = rf.predict(df_test)\n",
    "preds2 = gbc.predict(df_test)\n",
    "preds3 = model_l1.predict(df_test)\n",
    "preds4 = model.predict(df_test)\n",
    "preds4 = preds4 >= 0.5\n",
    "preds4 = np.multiply(preds4, 1)\n",
    "preds5 = neigh.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = majority_voting(preds1, preds2, preds3, preds4, preds5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_csv(r\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred[\"Prediction\"] = y_pred \n",
    "df_pred[\"Prediction\"].replace({0:False,1:True},inplace=True)\n",
    "df_pred[\"Prediction\"].replace({False:1,True:0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv(\"predictions.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
